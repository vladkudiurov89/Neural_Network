# -*- coding: utf-8 -*-
"""DZ - 8(PRO)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k7ltzdQwmInteC6quMX_e0HoroXw_XgC
"""

# Commented out IPython magic to ensure Python compatibility.
#Подключаем библиотеки
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import concatenate, Input, Dense, Dropout, BatchNormalization, Flatten, Conv1D, Conv2D, LSTM
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPooling2D, MaxPooling1D
from keras.utils import plot_model
from google.colab import files
from tensorflow.keras import utils
import os
import librosa
import numpy as np
import matplotlib.pyplot as plt
import time
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

import zipfile #Для разорхивации базы

#Разорхивируем архив с базой
z = zipfile.ZipFile('/content/drive/My Drive/datasets/voice/genres.zip', 'r')
z.extractall()
genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()

#Проверяем выгруженные папки
!ls genres 
#И одну из папок
!ls genres/blues

#Функция параметризации аудио
def get_features_2d(y, sr):
  #Получаем различные параметры аудио
  chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr) #Частота цветности
  rmse = librosa.feature.rmse(y=y) #Среднеквадратичная амплитуда
  spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr) #Спектральный центроид
  mfcc = librosa.feature.mfcc(y=y, sr=sr) #Мел спектральные коэффициенты
  
  #Возвращаем получившийся список
  return mfcc, chroma_stft, rmse, spec_cent

import time #Для подсчёта времени на обработку одного жанра

#Формируем обучающую выборку
#Создаём пустые листы
X_train_mfcc = []
X_train_chroma_stft = []
X_train_rmse = []
X_train_spec_cent = []
Y_train = []
#Запоминаем время старта формирования выборки
curr_time = time.time()

seconds = 20

#Проходим по всем жарнам
for i in range(len(genres)):
  g = genres[i] #Берём текущий жанр
  #Проходим по файлам папки, соответствующей текущему жанру
  for filename in os.listdir(f'./genres/{g}'):
    #Получаем имя песни
    songname = f'./genres/{g}/{filename}'
    #Загружаем в y аудиосигнал
    #Используем первые %seconds% секунд аудио
    y, sr = librosa.load(songname, mono=True, duration=seconds)

    #Превращаем сигнал в параметризованные данные
    for sec in range(seconds):
      mfcc, chroma_stft, rmse, spec_cent = get_features_2d(y[sec*sr:(sec+1)*sr], sr)
      X_train_mfcc.append(mfcc)
      X_train_chroma_stft.append(chroma_stft)
      X_train_rmse.append(rmse)
      X_train_spec_cent.append(spec_cent)
      Y_train.append(utils.to_categorical(i, len(genres)))

  #Выводим информацию о готовности обработки базы
  print("Жанр ", g, " готов -> ", round(time.time() - curr_time), "c", sep="")
  curr_time = time.time()

#Превращаем обучающую выборку на numpy массивы
X_train_mfcc = np.array(X_train_mfcc)
X_train_chroma_stft = np.array(X_train_chroma_stft)
X_train_rmse = np.array(X_train_rmse)
X_train_spec_cent = np.array(X_train_spec_cent)
Y_train = np.array(Y_train)

# Решейпим данные для нейронки
X_train_mfcc = X_train_mfcc.reshape(X_train_mfcc.shape[0], X_train_mfcc.shape[1], X_train_mfcc.shape[2], 1)
X_train_chroma_stft = X_train_chroma_stft.reshape(X_train_chroma_stft.shape[0], X_train_chroma_stft.shape[1], X_train_chroma_stft.shape[2], 1)
X_train_rmse = X_train_rmse.reshape(X_train_rmse.shape[0], X_train_rmse.shape[2], X_train_rmse.shape[1])
X_train_spec_cent = X_train_spec_cent.reshape(X_train_spec_cent.shape[0], X_train_spec_cent.shape[2], X_train_spec_cent.shape[1])

# Создаем маску для обучающей и проверочной выборки
val_mask = np.random.sample(20000)
train_mask = val_mask < 0.9
val_mask = val_mask >= 0.9

# Функция нормализации
def scale(X):
  min_X = X.min()
  max_X = X.max()
  X = (X - min_X) / (max_X - min_X)
  return X

# Нормализация
X_train_mfcc_scaled = scale(X_train_mfcc)
X_train_chroma_stft_scaled = scale(X_train_chroma_stft)
X_train_rmse_scaled = scale(X_train_rmse)
X_train_spec_cent_scaled = scale(X_train_spec_cent)

# Создаём модель

input_mfcc = Input((20, 44, 1))
input_chroma_stft = Input((12, 44, 1))
input_rmse = Input((44, 1))
input_spec_cent = Input((44, 1))

x1 = BatchNormalization()(input_mfcc)
x1 = Conv2D(256, (3,3), padding="same", activation="elu")(x1)
x1 = Conv2D(256, (3,3), padding="same", activation="elu")(x1)
x1 = MaxPooling2D(2)(x1)
x1 = Conv2D(128, (3,3), padding="same", activation="elu")(x1)
x1 = Conv2D(128, (3,3), padding="same", activation="elu")(x1)
x1 = MaxPooling2D(2)(x1)
x1 = Conv2D(64, (3,3), padding="same", activation="elu")(x1)
x1 = Conv2D(64, (3,3), padding="same", activation="elu")(x1)
x1 = Flatten()(x1)

x2 = BatchNormalization()(input_chroma_stft)
x2 = Conv2D(256, (3,3), padding="same", activation="elu")(x2)
x2 = Conv2D(256, (3,3), padding="same", activation="elu")(x2)
x2_gmp_1 = GlobalMaxPooling2D()(x2)
x2 = MaxPooling2D(2)(x2)
x2 = Conv2D(128, (3,3), padding="same", activation="elu")(x2)
x2 = Conv2D(128, (3,3), padding="same", activation="elu")(x2)
x2_gmp_2 = GlobalMaxPooling2D()(x2)
x2 = MaxPooling2D(2)(x2)
x2 = Conv2D(64, (3,3), padding="same", activation="elu")(x2)
x2 = Conv2D(64, (3,3), padding="same", activation="elu")(x2)
x2_gmp_3 = GlobalMaxPooling2D()(x2)
x2 = Flatten()(x2)

x3 = BatchNormalization()(input_rmse)
x3 = Conv1D(256, 3, padding="same", activation="elu")(x3)
x3 = Conv1D(256, 3, padding="same", activation="elu")(x3)
x3 = MaxPooling1D(2)(x3)
x3 = Conv1D(128, 3, padding="same", activation="elu")(x3)
x3 = Conv1D(128, 3, padding="same", activation="elu")(x3)
x3 = MaxPooling1D(2)(x3)
x3 = Conv1D(64, 3, padding="same", activation="elu")(x3)
x3 = Conv1D(64, 3, padding="same", activation="elu")(x3)
x3 = Flatten()(x3)

x4 = BatchNormalization()(input_spec_cent)
x4 = Conv1D(256, 3, padding="same", activation="elu")(x4)
x4 = Conv1D(256, 3, padding="same", activation="elu")(x4)
x4 = MaxPooling1D(2)(x4)
x4 = Conv1D(128, 3, padding="same", activation="elu")(x4)
x4 = Conv1D(128, 3, padding="same", activation="elu")(x4)
x4 = MaxPooling1D(2)(x4)
x4 = Conv1D(64, 3, padding="same", activation="elu")(x4)
x4 = Conv1D(64, 3, padding="same", activation="elu")(x4)
x4 = Flatten()(x4)

x = concatenate([x1, x2, x3, x4, x2_gmp_1, x2_gmp_2, x2_gmp_3])

x = Dense(128, activation='elu')(x)
x = Dense(10, activation='softmax')(x)

model = Model([input_mfcc, input_chroma_stft, input_rmse, input_spec_cent], x)

model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

plot_model(model, to_file='model.png')

from tensorflow.keras.callbacks import ReduceLROnPlateau

reduce_ = ReduceLROnPlateau(monitor='val_loss')
history = model.fit([X_train_mfcc_scaled[train_mask], X_train_chroma_stft_scaled[train_mask], X_train_rmse_scaled[train_mask], X_train_spec_cent_scaled[train_mask]],
                    Y_train[train_mask],
                    epochs=30,
                    batch_size=256,
                    validation_data=([X_train_mfcc_scaled[val_mask], X_train_chroma_stft_scaled[val_mask], X_train_rmse_scaled[val_mask], X_train_spec_cent_scaled[val_mask]],
                    Y_train[val_mask]),
                    callbacks=[reduce_])

plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])
plt.show()

