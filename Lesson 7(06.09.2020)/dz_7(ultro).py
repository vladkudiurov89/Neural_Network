# -*- coding: utf-8 -*-
"""DZ-7(ULTRO).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DnYYhbk7ONVH_TrPsdJe1UbLcxc7ma-m
"""

# Commented out IPython magic to ensure Python compatibility.
#Загружаем библиотеки
import pandas_datareader as pdr
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
from tensorflow.keras.layers import concatenate, Input, Dense, Dropout, BatchNormalization, Flatten, Conv1D, LSTM, SimpleRNN 
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from tensorflow.keras import utils
from tensorflow.keras.models import Sequential, Model 
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator
from keras.layers.wrappers import TimeDistributed
from keras.layers.core import Dense, Activation, Dropout
import time
import keras
from sklearn.metrics import mean_squared_error
import math
# %matplotlib inline

# Подключаем Диск
from google.colab import drive
drive.mount('/content/drive')

base_data = pd.read_csv('/content/drive/My Drive/datasets/date_csv/AAPL.csv')
base_data.head()

# Загружаем данные
def get_raw_data(index_name,retry_attempts = 3):   
    if index_name:
        while retry_attempts > 0 :
            try:
                df = pdr.get_data_yahoo(index_name)
                new_df = df.reindex(index=pd.date_range(df.index.min(), 
                                          df.index.max(), 
                                          freq='D')).fillna(method='ffill')
                retry_attempts = 0
                return new_df
            except:
                print("Data pull failed. {} retry attempts remaining".\
                      format(retry_attempts))
                retry_attempts = retry_attempts - 1
    else:
        print("Invalid usage. Parameter index_name is required")
    return None

# Просмотр данных
sp_df = get_raw_data('AAPL')
sp_close_series = sp_df.Close
plt.style.use('seaborn-poster')
sp_close_series.plot(figsize=(15, 7), color = 'teal')
sp_df.head()

sp_df.index.min(), sp_df.index.max()

# Подготавливаем, нормализуем, делим на выборки
WINDOW = 6
PRED_LENGTH = int(WINDOW/2)

def get_reg_train_test(timeseries,sequence_length= 51,
                   train_size=0.9,roll_mean_window=5,
                   normalize=True,scale=False):

    if roll_mean_window:
        timeseries = timeseries.rolling(roll_mean_window).mean().dropna()
    
    result = []
    for index in range(len(timeseries) - sequence_length):
        result.append(timeseries[index: index + sequence_length])
           
    if normalize:
        normalised_data = []
        for window in result:
            normalised_window = [((float(p) / float(window[0])) - 1) \
                                   for p in window]
            normalised_data.append(normalised_window)
        result = normalised_data
    
    result = np.array(result) 
    row = round(train_size * result.shape[0])
    
    train = result[:int(row), :]
    test = result[int(row):, :]
    
    scaler = None
    if scale:
        scaler=MinMaxScaler(feature_range=(0, 1))
        train = scaler.fit_transform(train)
        test = scaler.transform(test)
      
    x_train = train[:, :-1]
    y_train = train[:, -1]
        
    x_test = test[:, :-1]
    y_test = test[:, -1]
    
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))            
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1)) 
    return x_train,y_train,x_test,y_test,scaler

# Делим данные
x_train,y_train,x_test,y_test,scaler = get_reg_train_test(sp_close_series,
                                                      sequence_length=WINDOW+1,
                                                      roll_mean_window=None,
                                                      normalize=True,
                                                      scale=False)

print("x_train shape={}".format(x_train.shape))
print("y_train shape={}".format(y_train.shape))
print("x_test shape={}".format(x_test.shape))
print("y_test shape={}".format(y_test.shape))

# Функция создания сетки
def get_reg_model(layer_units=[100,100],dropouts=[0.2,0.2],window_size=50):

    model = Sequential()
    model.add(LSTM(layer_units[0], input_shape=(window_size,1), return_sequences=True))
    model.add(Dropout(dropouts[0]))
    model.add(LSTM(layer_units[1]))
    model.add(Dropout(dropouts[1]))

    model.add(Dense(1))
    model.add(Activation("linear"))
    
    start = time.time()
    model.compile(loss="mse", optimizer="rmsprop")
    print("> Compilation Time : ", time.time() - start)
    print(model.summary())
    return model

lstm_model=None
try:
    lstm_model = get_reg_model(layer_units=[50,100],
                           window_size=WINDOW)   
except:
    print("Model Build Failed. Trying Again")
    lstm_model = get_reg_model(layer_units=[50,100],
                           window_size=WINDOW)

# Обучение сети
callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=0)]
                                                                 
lstm_model.fit(x_train, y_train, epochs=20, batch_size=16, verbose=1,validation_split=0.05, callbacks=callbacks)

# Проверяем модель на обучающей выборке
def predict_reg_multiple(model, data, window_size=6, prediction_len=3):
    prediction_list = []
    for window in range(int(len(data)/prediction_len)):
        _seq = data[window*prediction_len]
        predicted = []
        for j in range(prediction_len):
            predicted.append(model.predict(_seq[np.newaxis,:,:])[0,0])
            _seq = _seq[1:]
            _seq = np.insert(_seq, [window_size-1], predicted[-1], axis=0)
        prediction_list.append(predicted)
    return prediction_list


train_pred_seqs = predict_reg_multiple(lstm_model, x_train, window_size=WINDOW, prediction_len=PRED_LENGTH)
train_offset = y_train.shape[0] - np.array(train_pred_seqs).flatten().shape[0]
train_rmse = math.sqrt(mean_squared_error(y_train[train_offset:], 
                                          np.array(train_pred_seqs).\
                                          flatten()))
print('Train Score: %.2f RMSE' % (train_rmse))

# Проверяем модель на тестовой выборке
test_pred_seqs = predict_reg_multiple(lstm_model, x_test, window_size=WINDOW,prediction_len=PRED_LENGTH)                                    
test_offset = y_test.shape[0] - np.array(test_pred_seqs).flatten().shape[0]
test_rmse = math.sqrt(mean_squared_error(y_test[test_offset:], 
                                          np.array(test_pred_seqs).\
                                          flatten()))
print('Test Score: %.2f RMSE' % (test_rmse))

# Отображение результатов
def plot_reg_results(predicted_data, true_data, prediction_len=3):
    fig = plt.figure(facecolor='white', figsize=(10, 9))
    ax = fig.add_subplot(111)
    ax.plot(true_data, 
            label='True Data',
            c='black',alpha=0.3)
    plt.plot(np.array(predicted_data).flatten(), 
             label='Prediction_full',
             c='c',linestyle='--')
    
    for i, data in enumerate(predicted_data):
        padding = [None for p in range(i * prediction_len)]
        plt.plot(padding + data, label='Prediction',c='black')

    plt.title("Forecast Plot with Prediction Window={}".format(prediction_len))
    plt.show()

plot_reg_results(test_pred_seqs,y_test,prediction_len=PRED_LENGTH)

