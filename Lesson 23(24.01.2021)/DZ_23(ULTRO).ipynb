{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DZ-23(ULTRO).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpn6tdMv1P2g"
      },
      "source": [
        "# Загружаем библиотеки\r\n",
        "from __future__ import absolute_import, division, print_function\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYyUhvfvEL94"
      },
      "source": [
        "dataset, info = tfds.load('fashion_mnist', as_supervised = True, with_info = True)\r\n",
        "dataset_test, dataset_train = dataset['test'], dataset['train']\r\n",
        "print(info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOfg98PsEMA4"
      },
      "source": [
        "def convert_types(image, label):\r\n",
        "    image = tf.cast(image, tf.float32)\r\n",
        "    image /= 255\r\n",
        "    return image, label\r\n",
        "\r\n",
        "batch_size = 128\r\n",
        "\r\n",
        "dataset_train = dataset_train.map(convert_types).shuffle(10000).batch(batch_size)\r\n",
        "dataset_test = dataset_test.map(convert_types).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyO-xzgbEMDk"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "datagen = ImageDataGenerator(rotation_range = 10, horizontal_flip = True, zoom_range = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50kKY5f2Eive"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, MaxPool2D, GlobalAveragePooling2D, Add\r\n",
        "from tensorflow.keras import Model\r\n",
        "\r\n",
        "class ResidualBlock(Model):\r\n",
        "    def __init__(self, channel_in = 64, channel_out = 256):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        channel = channel_out // 4\r\n",
        "        \r\n",
        "        self.conv1 = Conv2D(channel, kernel_size = (1, 1), padding = \"same\")\r\n",
        "        self.bn1 = BatchNormalization()\r\n",
        "        self.av1 = Activation(tf.nn.relu)\r\n",
        "        self.conv2 = Conv2D(channel, kernel_size = (3, 3), padding = \"same\")\r\n",
        "        self.bn2 = BatchNormalization()\r\n",
        "        self.av2 = Activation(tf.nn.relu)\r\n",
        "        self.conv3 = Conv2D(channel_out, kernel_size = (1, 1), padding = \"same\")\r\n",
        "        self.bn3 = BatchNormalization()\r\n",
        "        self.shortcut = self._shortcut(channel_in, channel_out)\r\n",
        "        self.add = Add()\r\n",
        "        self.av3 = Activation(tf.nn.relu)\r\n",
        "        \r\n",
        "    def call(self, x):\r\n",
        "        h = self.conv1(x)\r\n",
        "        h = self.bn1(h)\r\n",
        "        h = self.av1(h)\r\n",
        "        h = self.conv2(h)\r\n",
        "        h = self.bn2(h)\r\n",
        "        h = self.av2(h)\r\n",
        "        h = self.conv3(h)\r\n",
        "        h = self.bn3(h)\r\n",
        "        shortcut = self.shortcut(x)\r\n",
        "        h = self.add([h, shortcut])\r\n",
        "        y = self.av3(h)\r\n",
        "        return y\r\n",
        "    \r\n",
        "    def _shortcut(self, channel_in, channel_out):\r\n",
        "        if channel_in == channel_out:\r\n",
        "            return lambda x : x\r\n",
        "        else:\r\n",
        "            return self._projection(channel_out)\r\n",
        "        \r\n",
        "    def _projection(self, channel_out):\r\n",
        "        return Conv2D(channel_out, kernel_size = (1, 1), padding = \"same\")\r\n",
        "           \r\n",
        "class ResNet50(Model):\r\n",
        "    def __init__(self, input_shape, output_dim):\r\n",
        "        super().__init__()                \r\n",
        "        \r\n",
        "        self._layers = [\r\n",
        "            # conv1\r\n",
        "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\r\n",
        "            BatchNormalization(),\r\n",
        "            Activation(tf.nn.relu),\r\n",
        "            # conv2_x\r\n",
        "            MaxPool2D(pool_size = (3, 3), strides = (2, 2), padding = \"same\"),\r\n",
        "            ResidualBlock(64, 256),\r\n",
        "            [\r\n",
        "                ResidualBlock(256, 256) for _ in range(2)                \r\n",
        "            ],\r\n",
        "            # conv3_x\r\n",
        "            Conv2D(512, kernel_size = (1, 1), strides=(2, 2)),\r\n",
        "            [\r\n",
        "                ResidualBlock(512, 512) for _ in range(4)                \r\n",
        "            ],\r\n",
        "            # conv4_x\r\n",
        "            Conv2D(1024, kernel_size = (1, 1), strides=(2, 2)),\r\n",
        "            [\r\n",
        "                ResidualBlock(1024, 1024) for _ in range(6)                \r\n",
        "            ],\r\n",
        "            # conv5_x\r\n",
        "            Conv2D(2048, kernel_size = (1, 1), strides=(2, 2)),\r\n",
        "            [\r\n",
        "                ResidualBlock(2048, 2048) for _ in range(3)\r\n",
        "            ],\r\n",
        "            # last part\r\n",
        "            GlobalAveragePooling2D(),\r\n",
        "            Dense(1000, activation = tf.nn.relu),\r\n",
        "            Dense(output_dim, activation = tf.nn.softmax)\r\n",
        "        ]\r\n",
        "        \r\n",
        "    def call(self, x):\r\n",
        "        for layer in self._layers:\r\n",
        "            if isinstance(layer, list):\r\n",
        "                for l in layer:\r\n",
        "                    x = l(x)    \r\n",
        "            else:\r\n",
        "                x = layer(x)\r\n",
        "        return x\r\n",
        "       \r\n",
        "    \r\n",
        "model = ResNet50((28, 28, 1), 10)\r\n",
        "model.build(input_shape = (None, 28, 28, 1))\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lqVAV6qEiyY"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\r\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hElp4VOuEi1c"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\r\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\r\n",
        "\r\n",
        "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\r\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NN55gWOEi4P"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(image, label):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        predictions = model(image)\r\n",
        "        loss = loss_object(label, predictions)\r\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "    \r\n",
        "    train_loss(loss)\r\n",
        "    train_accuracy(label, predictions)\r\n",
        "        \r\n",
        "@tf.function\r\n",
        "def test_step(image, label):\r\n",
        "    predictions = model(image)\r\n",
        "    loss = loss_object(label, predictions)\r\n",
        "    \r\n",
        "    test_loss(loss)\r\n",
        "    test_accuracy(label, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xhEE7KlE6tz"
      },
      "source": [
        "import time\r\n",
        "import datetime\r\n",
        "\r\n",
        "PATH = '/tmp/mylogs/eager/'\r\n",
        "\r\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "loss_log_dir = PATH + current_time + '/data'\r\n",
        "loss_summary_writer = tf.summary.create_file_writer(loss_log_dir)\r\n",
        "\r\n",
        "num_epoch = 400\r\n",
        "start_time = time.time()\r\n",
        "\r\n",
        "train_accuracies = []\r\n",
        "test_accuracies = []\r\n",
        "\r\n",
        "for epoch in range(num_epoch):    \r\n",
        "    for image, label in dataset_train:\r\n",
        "        for _image, _label in datagen.flow(image, label, batch_size = batch_size):\r\n",
        "            train_step(_image, _label)\r\n",
        "            break\r\n",
        "        \r\n",
        "    for test_image, test_label in dataset_test:\r\n",
        "        test_step(test_image, test_label)\r\n",
        "        \r\n",
        "    train_accuracies.append(train_accuracy.result())\r\n",
        "    test_accuracies.append(test_accuracy.result())    \r\n",
        "    loss_summary_writer.flush()\r\n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}, spent_time: {} min'\r\n",
        "    spent_time = time.time() - start_time\r\n",
        "    print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100, test_loss.result(), test_accuracy.result() * 100, spent_time / 60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEqBQWnOE6w5"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNK8KRwnE60O"
      },
      "source": [
        "!ls /tmp/mylogs/eager"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07Oqt8fGE62-"
      },
      "source": [
        "%tensorboard --logdir '/tmp/mylogs/eager/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQXlfIWREi69"
      },
      "source": [
        "plt.plot(train_accuracies, label = 'Train Accuracy')\r\n",
        "plt.plot(test_accuracies, linestyle = 'dashed', label = 'Test Accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}