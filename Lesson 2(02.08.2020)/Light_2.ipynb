{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Light-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6smUKFD-8oJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pylab\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMLggyOr-N7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3c3b7bb1-19df-4a99-b88e-e96202e096a0"
      },
      "source": [
        "(x_train_mnist, y_train_mnist),(x_test_mnist, y_test_mnist) = mnist.load_data()\n",
        "\n",
        "x_train = x_train_mnist.reshape(60000, 784)\n",
        "x_test = x_test_mnist.reshape(10000, 784)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test.astype('float32')\n",
        "x_test = x_test / 255.\n",
        "\n",
        "y_train = utils.to_categorical(y_train_mnist, 10) \n",
        "y_test = utils.to_categorical(y_test_mnist, 10)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 784)\n",
            "(60000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD2venw9DaRt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3fe0d7e1-e8c9-4a5a-ae2d-01c7284d0f4e"
      },
      "source": [
        "data = []\n",
        "N = [50000, 10000, 500]\n",
        "\n",
        "for i in N:\n",
        "\n",
        "  x_val = x_train[i:int(i*1.2)]\n",
        "  y_val = y_train[i:int(i*1.2)]\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(800, input_dim=784, activation='relu'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(x_train[:i], y_train[:i], batch_size=128, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "  data = data + [['1-Dense', i, round(model.evaluate(x_test, y_test, verbose = 0)[1], 3)]]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2705 - accuracy: 0.9228 - val_loss: 0.1350 - val_accuracy: 0.9623\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1087 - accuracy: 0.9689 - val_loss: 0.0950 - val_accuracy: 0.9713\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0690 - accuracy: 0.9797 - val_loss: 0.0833 - val_accuracy: 0.9750\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0461 - accuracy: 0.9867 - val_loss: 0.0759 - val_accuracy: 0.9756\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0337 - accuracy: 0.9906 - val_loss: 0.0704 - val_accuracy: 0.9789\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 0.0700 - val_accuracy: 0.9791\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0174 - accuracy: 0.9955 - val_loss: 0.0755 - val_accuracy: 0.9782\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.0695 - val_accuracy: 0.9807\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.0820 - val_accuracy: 0.9783\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0807 - val_accuracy: 0.9792\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.5151 - accuracy: 0.8590 - val_loss: 0.2593 - val_accuracy: 0.9250\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.2207 - accuracy: 0.9384 - val_loss: 0.2139 - val_accuracy: 0.9405\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1559 - accuracy: 0.9556 - val_loss: 0.1787 - val_accuracy: 0.9505\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1149 - accuracy: 0.9686 - val_loss: 0.1728 - val_accuracy: 0.9510\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0833 - accuracy: 0.9781 - val_loss: 0.1730 - val_accuracy: 0.9500\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0622 - accuracy: 0.9848 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0480 - accuracy: 0.9891 - val_loss: 0.1559 - val_accuracy: 0.9565\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0360 - accuracy: 0.9919 - val_loss: 0.1513 - val_accuracy: 0.9590\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0287 - accuracy: 0.9949 - val_loss: 0.1712 - val_accuracy: 0.9555\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0213 - accuracy: 0.9972 - val_loss: 0.1533 - val_accuracy: 0.9580\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.8667 - accuracy: 0.5140 - val_loss: 1.4758 - val_accuracy: 0.6300\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9441 - accuracy: 0.8300 - val_loss: 1.0358 - val_accuracy: 0.7200\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5465 - accuracy: 0.8780 - val_loss: 0.8639 - val_accuracy: 0.7100\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3761 - accuracy: 0.9040 - val_loss: 0.7599 - val_accuracy: 0.7300\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2780 - accuracy: 0.9260 - val_loss: 0.6974 - val_accuracy: 0.7700\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2184 - accuracy: 0.9460 - val_loss: 0.6445 - val_accuracy: 0.7900\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1681 - accuracy: 0.9640 - val_loss: 0.5952 - val_accuracy: 0.8200\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1282 - accuracy: 0.9740 - val_loss: 0.5911 - val_accuracy: 0.8000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1014 - accuracy: 0.9840 - val_loss: 0.5886 - val_accuracy: 0.8200\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0770 - accuracy: 0.9940 - val_loss: 0.5760 - val_accuracy: 0.8200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovm2gmChpyRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "115ef56c-c175-4406-fa96-52df09c93439"
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Dense(800, input_dim=784, activation='relu'))\n",
        "model_2.add(Dropout(0.2))\n",
        "model_2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_2.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)\n",
        "\n",
        "data = data + [['1 - Dense + Drop', 50000, round(model_2.evaluate(x_test, y_test, verbose=1) [1], 3)]]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.2946 - accuracy: 0.9143 - val_loss: 0.1523 - val_accuracy: 0.9561\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.1248 - accuracy: 0.9637 - val_loss: 0.1046 - val_accuracy: 0.9693\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0848 - accuracy: 0.9747 - val_loss: 0.0863 - val_accuracy: 0.9748\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0620 - accuracy: 0.9816 - val_loss: 0.0805 - val_accuracy: 0.9758\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0470 - accuracy: 0.9858 - val_loss: 0.0767 - val_accuracy: 0.9767\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 0.0715 - val_accuracy: 0.9793\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0299 - accuracy: 0.9910 - val_loss: 0.0727 - val_accuracy: 0.9779\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0717 - val_accuracy: 0.9788\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0782 - val_accuracy: 0.9785\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0758 - val_accuracy: 0.9796\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WC3CFYfvkY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "1c40635e-bdfc-44af-d660-8bf47a424b1b"
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dense(800, activation='relu'))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dense(800, activation='relu'))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dense(800, activation='relu'))\n",
        "model_2.add(Dropout(0.2))\n",
        "\n",
        "model_2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_2.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)\n",
        "\n",
        "data = data + [['(BN+Dense+drop)*3', 50000, round(model.evaluate(x_test, y_test, verbose = 0)[1], 3)]]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.2675 - accuracy: 0.9197 - val_loss: 0.1180 - val_accuracy: 0.9653\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 15s 40ms/step - loss: 0.1248 - accuracy: 0.9608 - val_loss: 0.1121 - val_accuracy: 0.9691\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 15s 40ms/step - loss: 0.0940 - accuracy: 0.9719 - val_loss: 0.1091 - val_accuracy: 0.9716\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 15s 40ms/step - loss: 0.0717 - accuracy: 0.9763 - val_loss: 0.0983 - val_accuracy: 0.9748\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 15s 40ms/step - loss: 0.0655 - accuracy: 0.9798 - val_loss: 0.0988 - val_accuracy: 0.9747\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 15s 40ms/step - loss: 0.0576 - accuracy: 0.9818 - val_loss: 0.1061 - val_accuracy: 0.9763\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 15s 40ms/step - loss: 0.0493 - accuracy: 0.9847 - val_loss: 0.1041 - val_accuracy: 0.9764\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 15s 40ms/step - loss: 0.0497 - accuracy: 0.9848 - val_loss: 0.1116 - val_accuracy: 0.9736\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 15s 40ms/step - loss: 0.0420 - accuracy: 0.9875 - val_loss: 0.1112 - val_accuracy: 0.9780\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 15s 40ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.0952 - val_accuracy: 0.9778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j5PTwjXATgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8d23ec00-8e85-41d0-ea09-70020109c42a"
      },
      "source": [
        "df = pd.DataFrame(data, columns = ['model', 'size_data','val_accuracy'])\n",
        "df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>size_data</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-Dense</td>\n",
              "      <td>50000</td>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1-Dense</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1-Dense</td>\n",
              "      <td>500</td>\n",
              "      <td>0.844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1 - Dense + Drop</td>\n",
              "      <td>50000</td>\n",
              "      <td>0.982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(BN+Dense+drop)*3</td>\n",
              "      <td>50000</td>\n",
              "      <td>0.844</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               model  size_data  val_accuracy\n",
              "0            1-Dense      50000         0.980\n",
              "1            1-Dense      10000         0.957\n",
              "2            1-Dense        500         0.844\n",
              "3   1 - Dense + Drop      50000         0.982\n",
              "4  (BN+Dense+drop)*3      50000         0.844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}