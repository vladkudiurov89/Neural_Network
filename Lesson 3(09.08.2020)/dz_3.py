# -*- coding: utf-8 -*-
"""dz-3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q3_Q-E6QYuN6XOrier5EdLmpIYOwh6Z2
"""

# Commented out IPython magic to ensure Python compatibility.
from tensorflow.keras.datasets import mnist #Загружаем базу mnist
from tensorflow.keras.datasets import cifar10 #Загружаем базу cifar10
from tensorflow.keras.datasets import cifar100 #Загружаем базу cifar100
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.models import Sequential #Сеть прямого распространения
#Базовые слои для счёрточных сетей
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Activation
from tensorflow.python.keras.preprocessing.image import ImageDataGenerator # работа с изображениями
from tensorflow.keras.optimizers import Adam, Adadelta # оптимизаторы
from tensorflow.keras import utils #Используем дял to_categoricall
from tensorflow.keras.preprocessing import image #Для отрисовки изображений
from google.colab import files #Для загрузки своей картинки
import numpy as np #Библиотека работы с массивами
import matplotlib.pyplot as plt #Для отрисовки графиков
from PIL import Image #Для отрисовки изображений
import random #Для генерации случайных чисел 
import math # Для округления
import os #Для работы с файлами 
# подключем диск
from google.colab import drive

# %matplotlib inline

(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = mnist.load_data()

batch_size, img_rows, img_cols = 64, 28, 28
x_train = x_train_mnist.reshape(x_train_mnist.shape[0], img_rows, img_cols, 1 )
x_test = x_test_mnist.reshape(x_test_mnist.shape[0], img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test  = x_test.astype('float32')
x_train /= 255
x_test /= 255


y_train = utils.to_categorical(y_train_mnist, 10)
y_test = utils.to_categorical(y_test_mnist, 10)
# print(x_train.shape)
# print(x_test.shape)
# print(y_train.shape)
# print(y_test.shape)

def create_model():
  model = Sequential()

  model.add(Conv2D(32, (3,3), input_shape=(28,28,1)))
  BatchNormalization(axis=-1)
  model.add(Activation('relu'))
 
  model.add(Conv2D(32, (3,3)))
  BatchNormalization(axis=-1)
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  BatchNormalization(axis=-1)
  model.add(Conv2D(64, (3,3)))
  BatchNormalization(axis=-1)
  model.add(Activation('relu'))
  model.add(Conv2D(64, (3,3)))
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(Flatten())
  BatchNormalization()
  model.add(Dense(512))
  BatchNormalization()
  model.add(Activation('relu'))
  model.add(Dropout(0.2))
  model.add(Dense(10))
  model.add(Activation('softmax'))
  return model

model = create_model()
model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])
model.summary()
# model.fit(x_train, y_train, batch_size=batch_size, epochs=10, verbose=1, validation_data=(x_test, y_test))
score = model.evaluate(x_test, y_test, verbose=1)
# print(f'Model Loss: {score[0]}')
# print(f'Model score: {score[1]}')

(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()
fashion_mnist_labels = ["T-shirt/top",  # index 0
                        "Trouser",      # index 1
                        "Pullover",     # index 2 
                        "Dress",        # index 3 
                        "Coat",         # index 4
                        "Sandal",       # index 5
                        "Shirt",        # index 6 
                        "Sneaker",      # index 7 
                        "Bag",          # index 8 
                        "Ankle boot"]   # index 9
                        
print(f"X_train fashion shape:{X_train.shape}") 
print(f"Y_train Fashion shape:{Y_train.shape}")

X_train = X_train.astype('float32') / 255
X_test = X_test.astype('float32') / 255

(X_train, X_valid) = X_train[5000:], X_train[:5000] 
(Y_train, Y_valid) = Y_train[5000:], Y_train[:5000]

w, h = 28, 28
X_train = X_train.reshape(X_train.shape[0], w, h, 1)
X_valid = X_valid.reshape(X_valid.shape[0], w, h, 1)
X_test = X_test.reshape(X_test.shape[0], w, h, 1)

Y_train = utils.to_categorical(Y_train, 10)
Y_valid = utils.to_categorical(Y_valid, 10)
Y_test = utils.to_categorical(Y_test, 10)

print(f"X_train shape: {X_train.shape}") 
print(f"Y_train shape: {Y_train.shape}" )
print(f'train set: {X_train.shape[0]}')
print(f'validation set: {X_valid.shape[0]}')
print(f'test set: {X_test.shape[0]}')

model_ultra_pro = Sequential()

model_ultra_pro.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) 
model_ultra_pro.add(MaxPooling2D(pool_size=2))
model_ultra_pro.add(Dropout(0.3))
model_ultra_pro.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))
model_ultra_pro.add(MaxPooling2D(pool_size=2))
model_ultra_pro.add(Dropout(0.3))
model_ultra_pro.add(Flatten())
model_ultra_pro.add(Dense(256, activation='relu'))
model_ultra_pro.add(Dropout(0.5))
model_ultra_pro.add(Dense(10, activation='softmax'))
model_ultra_pro.summary()

model_ultra_pro.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model_ultra_pro.fit(X_train, Y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_valid, Y_valid))
score_1 = model_ultra_pro.evaluate(X_test, Y_test, verbose=1)

print(f'Model Loss: {score_1[0]}')
print(f'Model Score: {score_1[1]}')

(X_train10, Y_train10), (X_test10, Y_test10) = cifar10.load_data()
classes = ['самолет', 'автомобиль', 'птица', 'кот', 'олень', 'собака', 'лягушка', 'лошадь', 'корабль', 'грузовик']
def normalize(x):
    min_val = np.min(x)
    max_val = np.max(x)
    x = (x-min_val) / (max_val-min_val)
    return x

X_train10 = X_train10.astype('float32')
X_test10 = X_test10.astype('float32')
X_train10 = normalize(X_train10)
X_test10 = normalize(X_test10)
X_train10 = X_train10.reshape(-1,32, 32, 3)

Y_train10 = utils.to_categorical(Y_train10, 10)
Y_test10 = utils.to_categorical(Y_test10, 10)
print(f'Y_train shape: {Y_train10.shape}')
print(f'Y_test shape: {Y_test10.shape}')
print(f'X_train shape: {X_train10.shape}')
print(f'x_test: {Y_test10.shape}')

model_pro = Sequential()
model_pro.add(Conv2D(32, (3, 3), input_shape=X_train10.shape[1:]))
model_pro.add(MaxPooling2D(pool_size=2))
model_pro.add(Dropout(0.3))
model_pro.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))
model_pro.add(MaxPooling2D(pool_size=2))
model_pro.add(Dropout(0.3))
model_pro.add(Flatten())
model_pro.add(Dense(256, activation='relu'))
model_pro.add(Dropout(0.5))
model_pro.add(Dense(10, activation='softmax'))


model_pro.compile(optimizer="adam", loss="categorical_crossentropy",metrics=["accuracy"])
model_pro.summary()

model_pro.fit(X_train10, Y_train10, epochs=25, validation_data=(X_test10, Y_test10))
score_2 = model_pro.evaluate(X_test10, Y_test10, verbose=1)

print(f'Model Loss: {score_2[0]}')
print(f'Model Score: {score_2[1]}')