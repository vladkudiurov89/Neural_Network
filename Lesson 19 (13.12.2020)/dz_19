Домашнее задание к занятию: Обучение с подкреплением

Light задание

Запустите нейросеть на разном количестве тренировок, сравните результаты:
10 тренировок - количество выигранных очков?
20 тренировок - количество выигранных очков?
30 тренировок - количество  выигранных очков?
Проведите небольшую тренировочную сессию, изменив архитектуру нейросети:
Изменив количество связей в Dense слое
Добавив Dense слой
Добавив Conv слой
	Результаты сравните.
Постарайтесь обучить нейросеть до уровня игры, равного сопернику (или хотя бы, чтобы наша сеть набирала минимум 100 очков). Результат можно достичь большим количеством тренировок. Зафиксируйте какое количество тренировок/эпох и реального времени потребовалось нейросети для обучения.

PRO задание #1 
D-Q-learning. Текущий алгоритм нейросети предполагает предсказание действия агента по входным данным - состояние среды и вознаграждение. Измените алгоритм обучения сети так, чтобы на вход она получила состояние среды и действие, а предсказать должна вознаграждение. Сравните результаты подходов.

PRO задание #2 (альтернативное на выбор)
Выберите любую другую игру на платформе OpenAI Gym и обучите нейросеть решать задачу в новой игровой среде.

PRO задание #3 (альтернативное на выбор)
Напишите обучение игры с помощью генетического алгоритма и сравните его результаты с результатами нейросети на обучении с подкреплением.

Ultra PRO задание 1
Найдите на Kaggle или в другом источнике подходящую к задаче базу и реализуйте подход обучения с подкреплением с помощью полносвязных и сверточных слоев нейронных сетей.

Ultra PRO задание 2
Выберите любую другую игру на платформе OpenAI Gym и обучите нейросеть решать задачу в новой игровой среде. Добиться победы (или реального прогресса в работе агента)
