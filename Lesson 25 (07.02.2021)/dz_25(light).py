# -*- coding: utf-8 -*-
"""DZ-25(Light).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XkT_buYlnp8MLIxvdWtycSSotOKKdnjc
"""

# убеждаемся, что используем видеокарту
!nvidia-smi

# Commented out IPython magic to ensure Python compatibility.
 # Этим блоком будем визуализировать
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from PIL import Image
import scipy
 
# Библиотеки Pytorch
import torch 
import torchvision # здесь лежит mnist, cifar и много других датасетов и трансформаций для картинок
import torch.nn as nn # здесь лежат все слои
import torch.utils.data as data # работа с загрузчиком данных
import torchvision.transforms as transforms
import torchvision.datasets as dsets #работа с классом Датасет
from torch.autograd import Variable # для автоматического дифференциатора
import cv2
# Визуализации графа
from torch.utils.tensorboard import SummaryWriter 
import datetime,os
import time
 
import seaborn as sns
sns.set_style('darkgrid')

# подключаем Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Загружаем 10 картинок
PATH = '/content/drive/MyDrive/datasets/images/pict_1/'
# !ls '/content/drive/My Drive/datasets/images/pict_1/'

list_id = sorted(os.listdir(PATH))
labels = [0, 1, 1, 0, 0, 1, 1, 0, 0, 1]
print(list_id)

# Примеры изображений
img_1 = Image.open(PATH + list_id[0])
img_2 = Image.open(PATH + list_id[1])

fig, ax = plt.subplots(1, 2, figsize=(10, 6))
ax[0].imshow(img_1)
ax[1].imshow(img_2)
plt.show()

# Класс для работы с датасетом
class GetDataset(data.Dataset):

  def __init__(self, list_id, labels, PATH, transforms=None):
    self.list_id = list_id
    self.labels = labels
    self.transforms = transforms
    self.PATH = PATH

    print(self.list_id)
    print(self.labels)

  def __getitem__(self, index):
    id = self.list_id[index]
    image = cv2.imread(PATH + id)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    if self.transforms:
      image = self.transforms(image)

    x_train = image
    y_train = self.labels[index]

    return x_train, y_train

  def __len__(self):
    return(len(self.list_id))


# Класс модели
class GetModel(nn.Module):
  def __init__(self, input_size, hidden_size, num_classes):
    super().__init__()
    self.layer_1 = nn.Linear(input_size, hidden_size)
    self.relu = nn.ReLU()
    self.layer_2 = nn.Linear(hidden_size, num_classes)
    self.sigmoid = nn.Sigmoid()

  def forward(self, x):
    out = self.layer_1(x)
    out = self.relu(out)
    out = self.layer_2(out)
    out = self.sigmoid(out)
    return out

# преобразуем датасет, как необходимо по заданию
transform = transforms.Compose([
                                transforms.ToTensor(),
                                transforms.Grayscale(),
                                transforms.RandomHorizontalFlip(p=1.0),
                                transforms.Resize((32,32)),
                                transforms.Lambda(lambda x: torch.flatten(x))])

# Информация о датасете
custom_data = GetDataset(list_id[2:], labels[2:], PATH, transform)
len(custom_data)

# Создадим dataloader
trainLoader = torch.utils.data.DataLoader(dataset=custom_data,
                                          batch_size=4,
                                          shuffle=True,
                                          num_workers=4)

# Посмотрим на пример генерации
dataiter = iter(trainLoader)
images = dataiter.next()
print(images[0].shape, images[1].shape)
print(images)

# И на преобразование изображения
test_image = images[0][0].numpy().reshape(32,32)
plt.imshow(test_image, plt.cm.gray)
plt.show()

# объявляем константы
input_size = 1024
num_classes = 1
epochs = 20
learning_rate = 1e-3
hidden_size = 400
class_names = ['cross', 'ok']

# создаём модель
model = GetModel(input_size, hidden_size, num_classes)
print(images[0])
print(model(images[0]))

# компилируем модель
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
losses = []
model.train()

# # Сохранение и загрузка всей модели
# torch.save(linear, 'model.pkl')
# model = torch.load('model.pkl') # сохраняются даже состояния оптимизатора, результата эпох и т.д.

# # Рекомендуется сохранение только параметров модели (в целях безопасности)
# torch.save(linear.state_dict(), 'params.pkl')
# linear.load_state_dict(torch.load('params.pkl'))

# если есть видеокарта, работаем с моделью на ней
cuda = torch.cuda.is_available()
if cuda:
  model = model.cuda()

# обучаем модель
for epoch in range(epochs):
  lossTot = 0

  for i, (images, labels) in enumerate(trainLoader):
    labels = labels.view(-1,1).type(torch.FloatTensor)
    images = images.cuda()
    labels = labels.cuda()
    optimizer.zero_grad()
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss.backward()

    lossTot += loss.detach().data

    optimizer.step()

  losses.append(lossTot/len(custom_data))
  print(f'Epoch: {epoch+1}/{epochs}, loss: {losses[-1]}')

plt.plot(losses)
plt.show()

# проверяем работу модели
model.eval()

fig, ax = plt.subplots(1,2, figsize=(10,5))

for i, id in enumerate(list_id[:2]):
  test_image = cv2.cvtColor(cv2.imread(PATH + id), cv2.COLOR_BGR2RGB)
  test_image_for_predict = transform(test_image)
  test_image_for_predict = test_image_for_predict.cuda()
  prediction = model(test_image_for_predict).cpu().detach().numpy()[0]
  ax[i].imshow(test_image)
  ax[i].axis('off')
  ax[i].title.set_text(class_names[int(round(prediction))] + ' ' + str(round(prediction, 2)))

plt.show()