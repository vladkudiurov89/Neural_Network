{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DZ-4(LIGHT).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp4QrBpvBZRP"
      },
      "source": [
        "from google.colab import files # Для работы с файлами \n",
        "import numpy as np # Для работы с данными \n",
        "import pandas as pd # Для работы с таблицами\n",
        "import matplotlib.pyplot as plt # Для вывода графиков\n",
        "import os # Для работы с файлами\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras import utils # Для работы с категориальными данными\n",
        "from tensorflow.keras.models import Sequential # Полносвязная модель\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Embedding, Flatten, Dropout, Conv1D# Слои для сети\n",
        "from tensorflow.python.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.optimizers import Adam, Adadelta # Алгоритмы оптимизации, для настройки скорости обучения\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # Методы для работы с текстами и преобразования их в последовательности\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # Метод для работы с последовательностями\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder # Метод кодирования тестовых лейблов\n",
        "from sklearn.model_selection import train_test_split # Для разделения выборки на тестовую и обучающую\n",
        "from google.colab import drive # Для работы с Google Drive\n",
        "import time # Импортируем библиотеку time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g58hJZbWBpOU",
        "outputId": "19e4fb38-26ee-4658-fb31-1fac50880f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2OZkgOpBpRR"
      },
      "source": [
        "!unzip -q '/content/drive/My Drive/datasets/texts/Тексты писателей.zip' -d '/content/texts'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JDnoQdeBpUE",
        "outputId": "29c9dbe3-35de-41d8-8eea-1083f66ec43b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "# Запускаем все необходимые функции\n",
        "\n",
        "def readText(fileName): # Объявляем функции для чтения файла. На вход отправляем путь к файлу\n",
        "  f = open(fileName, 'r')        # Задаем открытие нужного файла в режиме чтения\n",
        "  text = f.read()                # Читаем текст\n",
        "  text = text.replace(\"\\n\", \" \") # Переносы строки переводим в пробелы\n",
        "  \n",
        "  return text                    # Возвращаем текст файла\n",
        "\n",
        "className = [\"О. Генри\", \"Стругацкие\", \"Булгаков\", \"Саймак\", \"Фрай\", \"Брэдберри\"] # Объявляем интересующие нас классы\n",
        "nClasses = len(className) # Считаем количество классов\n",
        "\n",
        "# Формирование обучающей выборки по листу индексов слов\n",
        "# (разделение на короткие векторы)\n",
        "def getSetFromIndexes(wordIndexes, xLen, step): # функция принимает последовательность индексов, размер окна, шаг окна\n",
        "  xSample = [] # Объявляем переменную для векторов\n",
        "  wordsLen = len(wordIndexes) # Считаем количество слов\n",
        "  index = 0 # Задаем начальный индекс \n",
        "\n",
        "  while (index + xLen <= wordsLen):# Идём по всей длине вектора индексов\n",
        "    xSample.append(wordIndexes[index:index+xLen]) # \"Откусываем\" векторы длины xLen\n",
        "    index += step # Смещаеммся вперёд на step\n",
        "    \n",
        "  return xSample\n",
        "\n",
        "# Формирование обучающей и проверочной выборки\n",
        "# Из двух листов индексов от двух классов\n",
        "def createSetsMultiClasses(wordIndexes, xLen, step): # Функция принимает последовательность индексов, размер окна, шаг окна\n",
        "\n",
        "  # Для каждого из 6 классов\n",
        "  # Создаём обучающую/проверочную выборку из индексов\n",
        "  nClasses = len(wordIndexes) # Задаем количество классов выборки\n",
        "  classesXSamples = []        # Здесь будет список размером \"кол-во классов*кол-во окон в тексте*длину окна (например, 6 по 1341*1000)\"\n",
        "  for wI in wordIndexes:      # Для каждого текста выборки из последовательности индексов\n",
        "    classesXSamples.append(getSetFromIndexes(wI, xLen, step)) # Добавляем в список очередной текст индексов, разбитый на \"кол-во окон*длину окна\" \n",
        "\n",
        "  # Формируем один общий xSamples\n",
        "  xSamples = [] # Здесь будет список размером \"суммарное кол-во окон во всех текстах*длину окна (например, 15779*1000)\"\n",
        "  ySamples = [] # Здесь будет список размером \"суммарное кол-во окон во всех текстах*вектор длиной 6\"\n",
        "  \n",
        "  for t in range(nClasses): # В диапазоне кол-ва классов(6)\n",
        "    xT = classesXSamples[t] # Берем очередной текст вида \"кол-во окон в тексте*длину окна\"(например, 1341*1000)\n",
        "    for i in range(len(xT)): # И каждое его окно\n",
        "      xSamples.append(xT[i]) # Добавляем в общий список выборки\n",
        "      ySamples.append(utils.to_categorical(t, nClasses)) # Добавляем соответствующий вектор класса\n",
        "\n",
        "  xSamples = np.array(xSamples) # Переводим в массив numpy для подачи в нейронку\n",
        "  ySamples = np.array(ySamples) # Переводим в массив numpy для подачи в нейронку\n",
        "  \n",
        "  return (xSamples, ySamples) # Функция возвращает выборку и соответствующие векторы классов\n",
        "\n",
        "# Создаем функцию подготовки данных\n",
        "def creat_train_data(maxWordsCount = 15000, xLen = 1000, step = 100):\n",
        "    tokenizer = Tokenizer(num_words=maxWordsCount)\n",
        "    tokenizer.fit_on_texts(trainText) # \"Скармливаем\" наши тексты, т.е. даём в обработку методу, который соберет словарь частотности\n",
        "\n",
        "    # Преобразовываем текст в последовательность индексов согласно частотному словарю\n",
        "    trainWordIndexes = tokenizer.texts_to_sequences(trainText) # Обучающие тесты в индексы\n",
        "    testWordIndexes = tokenizer.texts_to_sequences(testText)  # Проверочные тесты в индексы\n",
        "\n",
        "    #Формируем обучающую и тестовую выборку\n",
        "    xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step) #извлекаем обучающую выборку\n",
        "    xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, step)    #извлекаем тестовую выборку\n",
        "\n",
        "    # Преобразовываем полученные выборки из последовательности индексов в матрицы нулей и единиц по принципу Bag of Words\n",
        "    xTrain01 = tokenizer.sequences_to_matrix(xTrain.tolist()) # Подаем xTrain в виде списка, чтобы метод успешно сработал\n",
        "    xTest01 = tokenizer.sequences_to_matrix(xTest.tolist())   # Подаем xTest в виде списка, чтобы метод успешно сработал\n",
        "\n",
        "    return xTrain, xTrain01, yTrain, xTest, xTest01, yTest\n",
        "\n",
        "#Загружаем обучающие тексты\n",
        "\n",
        "trainText = [] #Формируем обучающие тексты\n",
        "testText = [] #Формируем тестовые тексты\n",
        "\n",
        "#Формирование необходимо произвести следующим образом \n",
        "#Класс каждого i-ого эллемента в обучающей выборке должен соответствовать \n",
        "#классу каждого i-ого эллемента в тестовой выборке\n",
        "\n",
        "for i in className: #Проходим по каждому классу\n",
        "  for j in os.listdir('texts/'): #Проходим по каждому файлу в папке с текстами #\n",
        "    if i in j: #Проверяем, содержит ли файл j в названии имя класса i\n",
        "      \n",
        "      if 'Обучающая' in j: #Если в имени найденного класса есть строка \"Обучающая\" \n",
        "        trainText.append(readText('texts/' + j)) #добавляем в обучающую выборку\n",
        "        print(j, 'добавлен в обучающую выборку') #Выводим информацию\n",
        "      if 'Тестовая' in j: #Если в имени найденного класса есть строка \"Тестовая\"\n",
        "        testText.append(readText('texts/' + j)) #добавляем в обучающую выборку\n",
        "        print(j, 'добавлен в тестовую выборку') #Выводим информацию\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(О. Генри) Обучающая_50 вместе.txt добавлен в обучающую выборку\n",
            "(О. Генри) Тестовая_20 вместе.txt добавлен в тестовую выборку\n",
            "\n",
            "(Стругацкие) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "(Стругацкие) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "\n",
            "(Булгаков) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "(Булгаков) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "\n",
            "(Клиффорд_Саймак) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "(Клиффорд_Саймак) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "\n",
            "(Макс Фрай) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "(Макс Фрай) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "\n",
            "(Рэй Брэдберри) Обучающая_22 вместе.txt добавлен в обучающую выборку\n",
            "(Рэй Брэдберри) Тестовая_8 вместе.txt добавлен в тестовую выборку\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr99_5z6BpWt"
      },
      "source": [
        "# Создаем функцию подготовки данных\n",
        "def creat_train_data(maxWordsCount = 15000, xLen = 1000, step = 100):\n",
        "    tokenizer = Tokenizer(num_words=maxWordsCount)\n",
        "    tokenizer.fit_on_texts(trainText)\n",
        "\n",
        "    # Преобразовываем текст в последовательность индексов согласно частотному словарю\n",
        "    trainWordIndexes = tokenizer.texts_to_sequences(trainText)\n",
        "    testWordIndexes = tokenizer.texts_to_sequences(testText)\n",
        "\n",
        "    #Формируем обучающую и тестовую выборку\n",
        "    xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\n",
        "    xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, step)\n",
        "\n",
        "    # Преобразовываем полученные выборки из последовательности индексов в матрицы нулей и единиц по принципу Bag of Words\n",
        "    xTrain01 = tokenizer.sequences_to_matrix(xTrain.tolist())\n",
        "    xTest01 = tokenizer.sequences_to_matrix(xTest.tolist())\n",
        "\n",
        "    return xTrain, xTrain01, yTrain, xTest, xTest01, yTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg8bs1qnBpaf"
      },
      "source": [
        "_, xTrain01, yTrain, _, xTest01, yTest = creat_train_data(maxWordsCount = 15000, xLen = 1000, step = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoKpDyUWC4HX"
      },
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(200, input_dim=15000, activation=\"relu\"))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(6, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suVOnHBuJxyy",
        "outputId": "bc2029a3-6e0c-4bef-c685-72e50f8595e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 200)               3000200   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 6)                 1206      \n",
            "=================================================================\n",
            "Total params: 3,002,206\n",
            "Trainable params: 3,001,806\n",
            "Non-trainable params: 400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5fex9FpKHWI",
        "outputId": "cf60d0a7-49f4-42d2-f41b-41fac07a3da3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "source": [
        "#Обучаем сеть на выборке, сформированной по bag of words - xTrain01\n",
        "history = model.fit(xTrain01, yTrain, epochs=10, batch_size=128, validation_data=(xTest01, yTest))\n",
        "\n",
        "plt.plot(history.history['accuracy'], \n",
        "         label='Доля верных ответов на обучающем наборе')\n",
        "plt.plot(history.history['val_accuracy'], \n",
        "         label='Доля верных ответов на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "120/120 [==============================] - 7s 58ms/step - loss: 0.0491 - accuracy: 0.9849 - val_loss: 0.3060 - val_accuracy: 0.9236\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 7s 56ms/step - loss: 4.0082e-04 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9242\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 7s 56ms/step - loss: 2.1820e-04 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9222\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 7s 57ms/step - loss: 1.3152e-04 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9206\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 7s 56ms/step - loss: 9.3321e-05 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9220\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 7s 56ms/step - loss: 7.1840e-05 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9240\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 7s 57ms/step - loss: 5.6511e-05 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9211\n",
            "Epoch 8/10\n",
            "120/120 [==============================] - 7s 57ms/step - loss: 4.5841e-05 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9217\n",
            "Epoch 9/10\n",
            "120/120 [==============================] - 7s 57ms/step - loss: 3.8364e-05 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9217\n",
            "Epoch 10/10\n",
            "120/120 [==============================] - 7s 57ms/step - loss: 3.2507e-05 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1fn48c9DWIUQtoBAWAVRSCBACChgEFGwRVSUArLztSiKlvoTl2oRUdQqLq1alWoElCKuSFErKiBQFRNkEVB2hATUgOwQyPL8/rh3hkkyIRfIMCE879drXpk5d5lnltxnzrnnniOqijHGGJNfmXAHYIwxpmSyBGGMMSYoSxDGGGOCsgRhjDEmKEsQxhhjgiob7gCKS61atbRx48bhDsMYY84qy5Yt26Wq0cGWlZoE0bhxY1JTU8MdhjHGnFVE5KfCllkTkzHGmKAsQRhjjAnKEoQxxpigLEEYY4wJyhKEMcaYoEKWIEQkWUR+FZHVhSwXEfmHiGwUkVUi0i5g2TAR2eDehoUqRmOMMYULZQ1iKtDrBMuvBpq7t1HASwAiUgN4COgIJAIPiUj1EMZpjDEmiJBdB6Gqi0Sk8QlWuRaYrs5449+ISDURqQt0Az5T1d8AROQznEQzM1SxlgSHj2Uz45ttHMjMCncoxpizTHRkBYZc0rjY9xvOC+XqA9sDHqe5ZYWVFyAio3BqHzRs2DA0UZ4BWTm53DbjOxauy0Ak3NEYY842F59ftdQliNOmqlOAKQAJCQln5cxHubnKve+uYuG6DB7vG8fAxLM30RljSpdw9mJKBxoEPI5xyworL5X+9t8feX95Ov/vygstORhjSpRwJog5wFC3N1MnYJ+q7gQ+Ba4Skeruyemr3LJS59XFm3ll0WaGXtKIMd2bhTscY4zJI2RNTCIyE+eEcy0RScPpmVQOQFVfBj4GfgdsBA4DI9xlv4nII0CKu6uJvhPWpcns5ek8+tEP/C7ufB66phViJx+MMSVMKHsxDSxiuQK3F7IsGUgORVwlwZfrM7j7nZVc0rQmz/aPJ6KMJQdjTMljV1KfYSu372X0m8u4sE4krwxtT4WyEeEOyRhjgrIEcQZtzjjIiKkp1KxSnqkjO1C1Yrlwh2SMMYWyBHGG/LI/kyGvfYsA00d2pHZkxXCHZIwxJ2QJ4gzYdySLYcnfsvfwMaaOSKRJrcrhDskYY4p0Vl8odzbIzMrhj9NT2ZRxkOThHYiLiQp3SMYY44kliBDKyVXGvrWCb7f8xj8GtqVr86DzghtjTIlkTUwhoqr89cPV/HfNz4zv3ZI+beqFOyRjjDkpliBC5O9fbODfS7cxutsFjOzSJNzhGGPMSbMEEQJvfvMTz32+gX7tY7inZ4twh2OMMafEEkQx++/qnYz/cDXdL6rN433jbAgNY8xZyxJEMfpm827ufGsFbRpU48Wb2lE2wt5eY8zZy45gxeSHnfv547RUGtY4j+RhHahU3obQMMac3SxBFIPtvx1mWPK3VKlYlukjE6leuXy4QzLGmNNmCeI07T54lGHJ35KZlcO0kYnUq1Yp3CEZY0yxsAvlTsOho9mMnJpC+t4jzLi5IxfWiQx3SMYYU2wsQZyiY9m5jJ7xHat37OeVwe1JaFwj3CEZY0yxCmkTk4j0EpF1IrJRRO4LsryRiHwhIqtEZKGIxAQs+5uIrHZv/UMZ58nKzVXufW8Vi9Zn8Nj1sfRoWSfcIRljTLELWYIQkQjgReBqoCUwUERa5lttMjBdVVsDE4HH3W1/D7QD4oGOwN0iUjVUsZ6sxz/5gQ+WpzOuZwv6d2gY7nCMMSYkQlmDSAQ2qupmVT0GvAVcm2+dlsB89/6CgOUtgUWqmq2qh4BVQK8QxurZlEWb+NfiLQy/tDG3dbsg3OEYY0zIhDJB1Ae2BzxOc8sCrQT6uvevByJFpKZb3ktEzhORWsDlQIP8TyAio0QkVURSMzIyiv0F5Pf+d2k89vGP/L51Xcb3bmlXSRtjSrVwd3O9G0gSkeVAEpAO5KjqPOBj4CtgJvA1kJN/Y1WdoqoJqpoQHR3aobQXrPuVe95dRedmNXnmD20oU8aSgzGmdAtlgkgn76/+GLfMT1V3qGpfVW0LPOCW7XX/TlLVeFW9EhBgfQhjPaHl2/Zw25vf0eL8SF4e3J4KZe0qaWNM6RfKBJECNBeRJiJSHhgAzAlcQURqiYgvhvuBZLc8wm1qQkRaA62BeSGMtVAbfz3IyKkp1K5agakjEomsWC4cYRhjzBkXsusgVDVbRMYAnwIRQLKqrhGRiUCqqs4BugGPi4gCi4Db3c3LAYvdNv79wGBVzQ5VrIX5eV8mw5K/JaKMMH1kItGRFc50CMYYEzaiquGOoVgkJCRoampqse1v35Es/vDy16TtOcysWy4htr7NJW2MKX1EZJmqJgRbZldSB5GZlcMfp6WyeddBpo5ItORgjDknWYLIJzsnlztnLiflp994fmBbOjerFe6QjDEmLMLdzbVEUVX++uEa5q39hYd6t6R363rhDskYY8LGEkSAZz/fwMxvt3H75RcwvHOTcIdjjDFhZQnC9cbXW/nHFxv4Q0IMd1/VItzhGGNM2FmCAD7+fifj56yhx8W1eez6OBtCwxhjsATBtt2HGfvWCto3rM7zA9tRNuKcf0uMMQawXkw0rHkej/WNo8fFtalU3obQMMYYn3M+QQDc2D6m6JWMMeYcY+0pxhhjgrIEYYwxJihLEMYYY4KyBGGMMSYoSxDGGGOCKjJBiEh/EXlXRK4QkR9F5FcRGXwmgjPGGBM+XmoQjwBvAe8BvXFmd7vfy85FpJeIrBORjSJyX5DljUTkCxFZJSILRSQmYNmTIrJGRH4QkX+IXd5sjDFnlJcEcUhV3wV+UtWNqvozcLSojUQkAngRuBpoCQwUkZb5VpsMTFfV1sBE4HF320uBzjjJKBboACR5e0nGGGOKg5cL5eqLyD+Auu5fAep72C4R2KiqmwFE5C3gWmBtwDotgbvc+wuA2e59BSoC5d3nKwf84uE5jTHGFBMvCWKc+3dZQJmXuT3rA9sDHqcBHfOtsxLoC/wduB6IFJGaqvq1iCwAduIkiBdU9QcPz2mMMaaYFJkgVHWaiJQHLnSL1qlqVjE9/93ACyIyHFgEpAM5ItIMuBjwnZP4TES6quriwI1FZBQwCqBhw4bFFJIxxhjw1oupG7AB53zCP4H1InKZh32nAw0CHse4ZX6qukNV+6pqW+ABt2wvTm3iG1U9qKoHgU+AS/I/gapOUdUEVU2Ijo72EJIxxhivvJykfhq4SlWTVPUyoCfwrIftUoDmItLErYEMAOYEriAitUTEF8P9QLJ7fxuQJCJlRaQczglqa2IyxpgzyEuCKKeq63wPVHU9zknjE1LVbGAM8CnOwf1tVV0jIhNFpI+7WjdgnYisB+oAk9zyd4FNwPc45ylWqup/vL0kY4wxxUFU9cQriCQDucCbbtEgIEJVR4Y4tpOSkJCgqalezp0bY4zxEZFlqpoQbJmXXkyjgduBO93Hi3HORRhjjCnFvCSIYar6DPBMqIMxxhhTcng5B3FryKMwxhhT4nipQVQTkb75C1X1/RDEY4wxpoTwkiCicAbpCxwsTwFLEMYYU4p5SRDbSlqPJWOMMaHn5RzEmpBHYYwxpsQpMkGo6mB33oYeACJSSUQiQx+aMcaYcPIyFtMfca5sfsUtiuH4sNzGGGNKKS9NTLfjTN6zH0BVNwC1QxmUMcaY8POSII6q6jHfAxEpi9OLyRhjTCnmJUF8KSJ/ASqJyJXAO4ANnGeMMaWclwRxH5CBM7LqLcDHwIOhDMoYY0z4eZlRLhf4F/Avd16HClrUELDGGGPOel56Mf1ZRFJFZCiwHtggIuOK2s4YY8zZzcuV1LfjzAY3H2gMZAKpwFOhC8sYY0y4eTkHsV9VU4FNqvqbqh7GSRJFEpFeIrJORDaKyH1BljcSkS9EZJWILBSRGLf8chFZEXDLFJHrTuqVGWOMOS1eahBNRWQO0MT9K0CTojYSkQjgReBKIA1IEZE5qro2YLXJwHRVnSYi3YHHgSGqugCId/dTA9gIzDuJ12WMMeY0eUkQ17p/nw4om+xhu0Rgo6puBhCRt9x9BSaIlsBd7v0FBL9C+0bgE7fmYowx5gzx0sR0uap+mf/mYbv6wPaAx2luWaCVgG+uieuBSBGpmW+dAcDMYE8gIqPcE+ipGRkZHkIyxhjjlZcE0SeEz383kCQiy4EkIB3I8S0UkbpAHPBpsI1VdYqqJqhqQnR0dAjDNMaYc4+XJqbaInJX/kJ3nuoTSQcaBDyOccsC97EDtwYhIlWAG1R1b8AqfwA+UNUsD3EaY4wpRl5qEBFAFSAy360oKUBzEWniXmA3AJgTuIKI1BIRXwz3A8n59jGQQpqXjDHGhJaXGsTPqjrxZHesqtkiMganeSgCSFbVNSIyEUhV1TlAN+BxEVFgEc41FwCISGOcGoiX8x3GGGOKmZcE8dmp7lxVP8YZuymwbHzA/Xdx5poItu1WCp7UNsYYc4Z4GYvpHhFpA3R1ixar6srQhmWMMSbcvIzFdCcwA2eSoNrAmyJyR6gDM8YYE15emphuBjqq6iEAEfkb8DXwfCgDM8YYE15eEoQQcG2Ce19CE47JLysri7S0NDIzPQ1/ZYwxQVWsWJGYmBjKlSvneRsvCeJ1YKmIfOA+vg547RTiM6cgLS2NyMhIGjdujIjlZWPMyVNVdu/eTVpaGk2aFDmUnl+R5yDcC+JGAL+5txGq+twpR2pOSmZmJjVr1rTkYIw5ZSJCzZo1T7olwksNAlX9DvjuVAIzp8+SgzHmdJ3KccTLldTGEBsbS8uWLYmPj6d+/fpMmDAh3CGZEubVV1+la9euJCQk2Pcjn23btjFkyBASExOJjY1l165d4Q7JE081CGMAPvnkExo1asTkyZM5ePBguMMxJchrr73GN998w9y5c4mKigp3OCVKZmYmAwcOZNKkSSQlJZ1VLQJeroNoGaSsW0iiMSVWVlYWFSpUKFCuqowbN47Y2Fji4uKYNWuWf9nChQuJiooiPj6e888/n8mTnWlEPvroI1q1akV8fDzR0dFMnTq1wH67detGixYtaNmyJZ06dWLHjh0ALFu2jKSkJNq3b0/Pnj3ZuXOnf/0//elPxMfHExsby7fffgvAhAkT/M8L0Lt3bxYuXAhAlSpVCjxvbGwsW7duJSUlhdatW5OZmcmhQ4do1aoVq1evLrD+M888Q2xsLLGxsTz3nHNqbty4cf7XXL9+feLj4xk/fnye96Np06Y884wz3mVOTg7jxo2jQ4cOtG7dmldeeQWAQYMGER8fT40aNWjSpAnx8fG8/PLLZGZmMmLECOLi4mjbti0LFiwAYOrUqURHR9OmTRuaNWvGzJkFhzGbOnUqY8aM8T8eM2aM//2fOHEiHTp0IDY2llGjRqGqBbbfunUr3bt3p3Xr1lxxxRVs27YNgClTprB9+3a6dOlCp06dWLVqFbm5uTRv3hzfUPy5ubk0a9aMjIwMunXrRmpqaoGY/vOf/9CxY0fatm1Ljx49+OWXXwqsM2nSJC688EJiY2N5+OGH/bEFfp6+zzH/azx06BAjR44kMTGRtm3b8uGHH/r3LyL8+OOPAPzwww+ISKHfTV/sgc978OBBrrjiCtq1a0dcXJx/3/Pnz+fIkSOMGTOGuLg47r33Xv+2M2fOJC4ujtjY2DzlVapU4c9//jOtWrXiiiuu8L+HmzZtolevXrRv356uXbv64w0VLzWIt0XkDeBJoKL7NwG4JJSBmYIe/s8a1u7YX6z7bFmvKg9d06rI9Q4cOEBkZMExGt9//31WrFjBypUr2bVrFx06dOCyyy6jbt265OTkkJSUxJw5c/I0OYwfP55p06aRkJCQ52CV34wZM2jfvj19+vQhNTWVq6++mjvuuIMPP/yQ6OhoZs2axQMPPEBysjPG4+HDh1mxYgWLFi1i5MiRQQ/oXnXo0IE+ffrw4IMPcuTIEQYPHkxsbGyedZYtW8brr7/O0qVLUVU6duxIUlISTz3lTNc+YcIEqlSpwt133w04CbNr167MnTuXlJQUbrnlFu666y5ee+01oqKiSElJ4ejRo3Tu3JmrrrqKGTNmADB8+HB69+7NjTfeCMDTTz+NiPD999/z448/ctVVV7F+/XoA+vfvzwsvvMA777zDzJkzGThwoOfXPGbMGMaPd0bCGTJkCHPnzuWaa67Js84dd9zBsGHDGDZsGMnJydx5553Mnj2bX3/9ld/97nc89NBDzJ8/n6FDh7JixQoGDx7MjBkzGDt2LJ9//jlt2rQhOjqaMmXKBE1AXbp04ZtvvkFEePXVV3nyySd5+unjc5V9+eWXvPbaayxfvpyKFSvSrVs3OnfuTI8ePTy9xkmTJtG9e3eSk5PZu3cviYmJ/m0TExNJTk7mySefJDk5mY4dO3p+78DpRvrBBx9QtWpVdu3aRadOnejTpw8ZGRmkp6ezevVqqlevzlVXXcXs2bNJTEzk3nvvZdmyZXnKr7vuOg4dOkRCQgLPPvssEydO5OGHH+aFF15g1KhRvPzyyzRv3pylS5dy2223MX/+/JOK82R4SRAdgb8BX+GM4joD6ByyiEyJk5OTw4EDB6hcuXKBZUuWLGHgwIFERERQp04dkpKSSElJoU+fPhw5coSKFSsW2CYiIoIDBw4U+byDBg3i6NGjVK1alR49erBu3TpWr17NlVde6Y+rbt26/vV9B8PLLruM/fv3s3evM3L8s88+y5tvvgnAli1b/AfsI0eOEB8fj6qSlJTkrwH4jB8/ng4dOlCxYkX+8Y9/BH3t119/vf996du3L4sXL6Zt27aFvqbFixcTHx/Pxo0beeGFFwCYN28eq1at4t13nWHJ9u3bx4YNGwrtjrhkyRLuuMMZzOCiiy6iUaNG/gQxa9YsFi1axNatW3nvvfeCbj9r1iyWLFkCQHp6OgkJCQAsWLCAJ598ksOHD/Pbb7/RqlWrAgni66+/5v333wecJHLPPfcATk1yyJAhAHTv3p3du3ezf/9+Ro4cybXXXsvYsWNJTk5mxIgRAMTExLB8+XI6dOiQZ/9paWn079+fnTt3cuzYsTzvwaxZs5g9ezb9+vXzN2MNGDCARYsWeU4Q8+bNY86cOf5aZWZmpr8W1KFDB5YvX05mZiYrVqzwvy/BDBo0iEqVKgHO98j3HvzlL39h0aJFlClThvT0dH755RdUlZ49e+Kbs2bQoEEsWrQIEaFbt24Fyq+77jrKlClD//79ARg8eDB9+/bl4MGDfPXVV/Tr188fx9GjRz297lPlJUFkAUeASjg1iC2qmhvSqExQXn7ph8LmzZu58MILT3q7HTt2UK9evQLlTz/9NEOGDKFixYrs3r270H/EGTNmkJCQwIMPPshzzz3HNddcQ6tWrfj666+Drp+/bdf3+M9//rM/KfTu3du/vFKlSqxYsYLs7Gx69OjB559/nmf73bt3c/DgQbKyssjMzAyaIE+Wrwaxa9cu2rdvz4ABA1BVnn/+eXr27Hna+/fVIDZs2EDv3r1Zt25doesA/hpcZmYmt912G6mpqTRo0IAJEyacVJfIqlWrBi1v0KABderUYf78+Xz77bf+WtFf/vIXhg0bxosvvsiePXvo08eZl+yOO+7grrvuok+fPixcuDBPzbN///60b9+eVatWeY4rP1Xlvffeo0WLFnnKly5dCkCvXr244447uPrqq9m8eXOh+/F9N+F4E9OMGTPIyMhg2bJllCtXjsaNG5OZmVnoe3MyRITc3FyqVavGihUrTnt/XnnpxZSCkyA64AzYN1BE3glpVKZEefvtt7nkkuAtil27dmXWrFnk5OSQkZHBokWLSExMJCcnh/fff5/OnQtWNuvXr0/dunVJTU31/0o6EV+VvUWLFmRkZPgTRFZWFmvWrPGv5zv/sWTJEqKiojyfLC1btixRUVEcO3YsT/ktt9zCI488wqBBg/K0Dwe+9tmzZ3P48GEOHTrEBx98QNeuXQusF8x5553HkSNHOHr0KD179uSll14iK8uZF2v9+vUcOnSo0G27du3qP9CuX7+ebdu2FTjgRUZGsnv3bk+xAP5kUKtWLQ4ePOivzeR36aWX8tZbbwHOAdH3ejt27OiPaeHChdSqVct/YLz55psZPHgw/fr1IyIiAnBqPkuXLmXlypVMnHh8NoF9+/ZRv74ziPO0adMKPP9ll13GRx99xL59+zh27BizZs2iW7dunl9nz549ef755/3NW8uXL8+zfMiQIXz11VcMHjzY8z4DY69duzblypVjwYIF/PTTTwC0b9+e+fPns2vXLnJycpg5cyZJSUkkJiby5ZdfFigH53yN7zP497//TZcuXahatSpNmjThnXecw6+qsnJlaMdN9VKD+D9V9Z2R2QlcKyJDQhiTKUFeeuklHnzwQRo1auRvlsjIyCAnJ4d27dpx/fXX8/XXX9OmTRtEhCeffJLzzz+fm266iebNm3PDDTfk2d/Ro0cZNmwYr776atCTxIF81fhKlSrx73//m/Lly/Puu+9y5513sm/fPrKzsxk7diytWjk1q4oVK9K2bVuysrL85yVO5MiRI3Tp0oWsrCwaN25Mz549ue+++wCYPn065cqV46abbiInJ4dLL72U+fPn0717d//27dq1Y/jw4SQmJgLOgfBEzUtwvIkpMzOTu+66i6ioKG6++Wa2bt1Ku3btUFWio6OZPXt2ofu47bbbGD16NHFxcZQtW5apU6f6OxD4mo+OHj2ap+2+KNWqVeOPf/wjsbGxnH/++QWafnyef/55RowYwVNPPUV0dDSvv/46AI888gjDhw+ndevWVKlSJc/BvU+fPowYMcLfvHQiEyZMoF+/flSvXp3u3buzZcuWPMsvuOACxo0bR+fOnRER+vfv7/9MfJ8nOE2J/fr1o0KFCmzevJl58+bRq1cv/vrXvzJ27Fhat25Nbm4uTZo0Ye7cuf79165dO8+PjpMxaNAgrrnmGuLi4khISOCiiy4CoFGjRkyYMIHLLruMiIgIfv/733PttdcC8MQTT3D55ZejqnnKK1euzLfffsujjz5K7dq1/T9+ZsyYwejRo3n00UfJyspiwIABtGnT5pTi9URVT3gDGga7FbXdmb61b99eS6O1a9eG9fkfeughff311z2Xh0tSUpKmpKSEOwwTREpKinbp0iWsMQwbNky3bNkS1hhORuXKlUOy32DHE5wJ3IIeV73UID4CFGeAvsC/rYvaUER6AX/HmVHuVVV9It/yRjjTjEbjDOMxWFXT3GUNgVdxZpVT4HfqTCJkjDlLPPHEE7z00kv+5qdwueGGG6hevXpYYzgbiQbpahZ0ReeMXw+gHDBPVbOLWD8CWA9cCaThnMsYqKprA9Z5B5irqtNEpDvOOE9D3GULgUmq+pmIVAFyVfVwYc+XkJCggX2TS4sffviBiy++OGzPn52djYj4246LKjfGlFzBjiciskxVg/YUOZkrqZ8F2gD7gMHATUWsnwhsVNXNbhBvAdcCawPWaQnc5d5fAMx2120JlFXVzwBU1S7bDZOyZYN/RQorN8aUHiczFlM34ApVvQ5o6mH9+sD2gMdpFJxjeiXQ171/PRApIjWBC4G9IvK+iCwXkafcGkkeIjJKRFJFJNV3paExxpjicTIJIlePX/9w7IRrenc3kCQiy4EkIB1nQqKyOF1q78bpXtsUGJ5/Y1WdoqoJqprgu9jEGGNM8SiynUBEDuCcJD5PRPbjnKQueHlsQek4J5h9YtwyP1XdgVuDcM8z3KCqe0UkDVgR0Dw1G+iETVRkjDFnjJcJgyJVtaqqlnX/RqqqlznrUoDmItJERMoDA4A5gSuISC0R8cVwP06PJt+21UTEVy3oTt5zF+YMs+G+jQmNI0eOcP/999OpUyfi4+P5+OOPwx2Sn5caxGXBylV10Ym2U9VsERkDfIrTzTVZVdeIyEScfrdzcM5rPC4iCiwCbne3zRGRu4Ev3N5Ty4B/eX9ZJhRsuG9jit8tt9xCly5dmDhx4knNF30meDkHMc69fRhw/24vO1fVj1X1QlW9QFUnuWXj3eSAqr6rqs3ddW5W1aMB236mqq1VNU5Vh6tqcZ33MKfAhvu24b7BGVnWF0t8fDyVKlVi69atbN26lYsuuohBgwZx8cUXc+ONN3L4sNMr/YsvvqBt27bExcUxcuRI/wBzjRs3Ji4ujosuuoirrrrKP7zIvHnzuOSSS2jXrh39+vXz/xhp3Lgx99xzD3FxcSQmJrJx40ag8CHICxtSfPjw4XmGEgkcGjzY57l161ZEhJdfftn/edWvX5/hw4cXeH9O9H0bPXo0CQkJtGrVioceeghwhghfuHAhycnJ/pEJ9uzZA8CKFSvo1KkTrVu3zlNe2He9sKHMT0eRNQhVvQZARJb77psw+eQ++Pn74t3n+XFw9RNFrmbDfdtw3z5PPfWUP5bA92TdunW89tprdO7cmZEjR/LPf/6TMWPGMHz4cL744gsuvPBChg4dyksvvcTYsWMBZwTZ6tWr065dOzZt2kS9evV49NFH+fzzz6lcuTJ/+9vfeOaZZ/xxRUVF8f333zN9+nTGjh3L3LlzCx2CvLAhxQtT2OdZvXp1mjVrxuzZs7n11lv573//S4MGDYreYT6TJk2iRo0a5OTkcMUVV7Bq1SqioqLYvn07b7zxBklJSYwfP56HH36Y5557jqFDh/L8888XKIfg3/XChjI/nUEmT6YXk/d32pQqpzLcN1Asw303adKEn376qcBw3/Hx8Tz66KOkpaX51z/RcN++X7yLFy/2r+8b7rtNmzbceeed5ObmHaR4/PjxfPbZZ6SmpvqHtc7/2n3DfVepUsU/3PeJ+MZiuvzyy7nzzjsB5xfz9OnTiY+Pp2PHjuzevZsNGzYUuo8lS5b4B5MLNtx369at+b//+z9Gjx4ddPtZs2b534/AGt+CBQvo2LEjcXFxzJ8//6THJGrQoIF/cMbBgwezZMkS1q1bR5MmTfyjAQ8bNoxFi463Tl9++eX+EV/j4uL45ptvWLt2LZ07dyY+Pp5p06b5B72D45/xwIED/YM2fv3119x0k3NZ1pAhQzFbDagAABfpSURBVPxjhvmGFA/GV8uLj49n06ZNwIk/zwoVKtCsWTPWrFnDG2+84R/aPJjCvm9vv/027dq1o23btqxZs4a1a9eiqjRo0MA/SJ/v/dm3bx979+4tUJ7/fQj8rs+bN48nnniC+Ph4unXrlmco81Pl5RyE70K22gH3UdVnTuuZzcnz8Es/FGy4bxvu24vC3v8TWbBgATVr1mTo0KHMnDmTyMhIrrzyyqDNY/n3WdT+CxtSHAqvBZ3IiBEjePLJJ8nOzqZOnTqFrhfs+7ZlyxYmT55MSkoK1atXZ/jw4ac1FHiw91oLGcr8dHipQUS6t38F3C/Y1mBKLRvu24b79mLbtm3+z8Y3RHWLFi3YunWr/3yBryklkIgQGRnpn4Xtf//7n3/9Q4cO+WtHcPwznjVrlv87WdgQ5IUNKV6Yoj7P9u3b8+uvv3oalTa//fv3U7lyZaKiovjll1/45JNPAKhRowYVKlTw1zR8709UVBTVq1cvUJ7/fQj8rhc1lPmp8HIO4mEAEanqPNSi2wZMqWHDfdtw3161aNGCF198kZEjR9KyZUtGjx5NxYoVef311+nXrx/Z2dl06NCBW2+91b/N5ZdfjohQp04dHnvsMapVq8bUqVMZOHCg/2T2o48+6q/B7tmzh9atW1OhQgV/LaOwIchPVmGfp+8ENuA/sJ9sAm3Tpg1t27bloosuytMUB87B//bbbycrK4tmzZrx2mvO5V7Tpk3j1ltv5fDhwzRt2jTP6wr2XS9qKPNTUtgwr74bzvzT3wNb3dtKoH1R253pmw33HRo23LfxYsuWLdqqVauQPkejRo00IyMjpM9xNjid73oohvtOBm5T1cUAItIFeB0Pw30bY4w5exU53LfbvbVtvrLvVLVdSCM7STbcd2jYcN/GlB6hGO77SxF5BZiJ09W1P7BQRNoBqOp3pxeyKclsuG9jzl1e/st9E54+lK+8LU7C6I4JKVX11GXQGGMKU1RrUTBeejFdfkrRmGLhu1agZs2aliSMMadEVdm9e3fQC1dPxMuFcnWAx4B6qnq1O9vbJapqQ2+fATExMaSlpWETIhljTkfFihWJiYk5qW28NDFNxem19ID7eD0wC5ub4YwoV64cTZo0CXcYxphzkJcrqWup6ttALjjDeOPM+maMMaYU85IgDrnzRCuAiHQC9oU0KmOMMWHnJUHchTMT3AUi8j9gOnCHl52LSC8RWSciG0XkviDLG4nIFyKySkQWikhMwLIcEVnh3ubk39YYY0xoeenF9J2IJAEtcOajXqeqWUVtJyIRwIvAlUAakCIic1Q1cOrQycB0VZ0mIt2BxwHfOLpHVDX+5F6OMcaY4lJkDUJEzgd6AZuAa3CmCG3kYd+JwEZV3azObHBvAdfmW6clMN+9vyDIcmOMMWHipYnpfWAU8A1wHvAL8G8P29UHtgc8TnPLAq0E+rr3rwci3fMdABVFJFVEvhGR6zw8nzHGmGLkpZtrVVW9VES2qOpfAUTkpmJ6/ruBF0RkOLAISOd4D6lGqpouIk2B+SLyvapuCtxYREbhJC8aNmxYTCEZY4wBbwkiwh136aiItMWpdXi5HC8dCJy4NcYt81PVHbg1CBGpAtygqnvdZenu380ishBnaI9N+bafAkwBZ7A+DzEZY4zxyEsT08/A08BO4BmcE8s/e9guBWguIk1EpDwwAKc3lJ+I1BIRXwz34wwtjohUF5EKvnWAzkDgyW1jjDEhFrKxmFQ1W0TGAJ8CEUCyqq4RkYk4E1TMAbrhnPRWnCam293NLwZeEZFcnCT2RL7eT8YYY0KsyPkgzhaldT4IY4wJpRPNB+GlickYY8w5yBKEMcaYoLwM9z00WLmqTi/+cIwxxpQUXmoQk4EEoAPwlPs3aHuVMcaY0sPLdRDpqnongIj0AO5V1cOhDcsYY0y4ealBlBORtu6AfRWBz0TkohDHZYwxJsy81CDuBf4FZOOMtLoDZ5a5y0IXljHGmHDzcqHcR8BHgWVuU5MxxphSzEsvprsKWfRMMcdijDGmBPFyDmIcEBnkZowxphTzcg5ip6o+HPJIjDHGlCheEkRTEZkNZOKcoP6fqr4X2rCMMcaEm5cEcS3OaKyVgHrAzSJymar+KaSRGWOMCSsvvZi+DHwsIsmADbNhjDGlnJcaBCJSB2eIDYBvVXVQ6EIyxhhTEhTZi0lE/gB8C/QD/gAsFZEbQx2YMcaY8PLSzfUBoIOqDlPVoUAi8FcvOxeRXiKyTkQ2ish9QZY3EpEvRGSViCwUkZh8y6uKSJqIvODl+YwxxhQfLwmijKr+GvB4t5ftRCQCeBG4GmgJDBSRlvlWmwxMV9XWwETg8XzLH8GZitQYY8wZ5iVB/FdEPhWR4SIyHGfYjU88bJcIbFTVzap6DHgLp0dUoJbAfPf+gsDlItIeqAPM8/BcxhhjilmRCUJVxwGvAK3d2xRVvcfDvusD2wMep7llgVYCfd371wORIlJTRMoATwN3n+gJRGSUiKSKSGpGRoaHkIwxxnjlqReTqr4PvO97LCK9gRruwzdUVU/x+e8GXnBrJouAdCAHuA34WFXTROREcU0BpgAkJCScagzGGGOCKDRBiMj4E2x3K06tAkCAYAfndKBBwOMYt8xPVXfg1iBEpApwg6ruFZFLgK4ichtQBSgvIgdVtcCJbmOMMaFxohrEKODZQpbleBifKQVoLiJNcBLDAOCmwBVEpBbwm6rmAvcDyQCB11m4tYsESw7GGHNmnShBZKjq08EWiMjgonasqtkiMgb4FGeojmRVXSMiE4FUVZ0DdAMeFxHFaWK6/WRfgDHGmNCQwk4fiMhqoBdwDDigqkcCln2nqu3OTIjeJCQkaGpqarjDMMaYs4qILFPVhGDLijpJ/TFQHqd3URVgPfA1UK14QzTGGFPSFJogVDU28LHb9bQp0B9oLCJD3UWn04vJGGNMCeWpmyuAeyJ5IzBJRHYDTXB6LxXWi8kYY8xZzHOCCKSqLxd3IMYYY0oWL0NtGGOMOQdZgjDGGBOUJQhjjDFBWYIwxhgTlCUIY4wxQVmCMMYYE5QlCGOMMUFZgjDGGBOUJQhjjDFBWYIwxhgTlCUIY4wxQVmCMMYYE1RIE4SI9BKRdSKyUUQKTBkqIo1E5AsRWSUiC0UkJqD8OxFZISJrROTWUMZpjDGmoJAlCBGJAF4ErgZaAgNFpGW+1SYD01W1NTAReNwt3wlcoqrxQEfgPhGpF6pYjTHGFBTKGkQisFFVN6vqMeAt4Np867QE5rv3F/iWq+oxVT3qllcIcZzGGGOCCOWBtz6wPeBxmlsWaCXQ171/Pc7UpjUBRKSBiKxy9/E3Vd2R/wlEZJSIpIpIakZGRrG/AGOMOZeF+5f53UCSiCwHkoB0IAdAVbe7TU/NgGEiUif/xqo6RVUTVDUhOjr6TMZtjDGlXigTRDrQIOBxjFvmp6o7VLWvqrYFHnDL9uZfB1gNdA1hrMYYY/IJZYJIAZqLSBMRKQ8MAOYEriAitUTEF8P9QLJbHiMildz71YEuwLoQxmqMMSafkCUIVc0GxgCfAj8Ab6vqGhGZKCJ93NW6AetEZD1QB5jkll8MLBWRlcCXwGRV/T5UsRpjjClIVDXcMRSLhIQETU1NDXcYxhhzVhGRZaqaEGxZuE9SG2OMKaEsQRhjjAnKEoQxxpigLEEYY4wJyhKEMcaYoCxBGGOMCcoShDHGmKDKhjuAUiknG7IOQ9aRgL+++4eDLzt2CHKzISoGalwANS+Aag0holy4X40JN1U4/BtUiISy5cMdjTmHWILIyYYdyyHrUPAD+rHDQQ7yRwo50Lt/c46dfBwR5aFMWWcfPmXKQrVGTrLwJQ3f/agYKBNRfO+DCb/Dv8HuTfDbpoC/G2H3Zjh2ACIqQN02UL+9e2sHNZqCSLgjN6WUJYisw/BajxOvU7YilKsE5c5zb+798lWgcm0oH1BW4G+Qsvzrl60EEWXdX4q7nYPD7o15DxRb/+ckMZ+I8lC9CdRsBjWbBiSQZhBZ1w4aJVXm/oDPdbObANzP+Mie4+tJGacGWeMCaNARqjeGAzshbRl8Nw2WvuSsV6k61GsHMQlO0qjXDqrYyMameNhQG7k5sGmBe8AOOGiXr3z84F2mBJyqUYUDPx8/uOze6B5g3ANNztHj65Y7z/llWaOpm0ACaiCVoy15hNqxw85nElgD8H1uh37Nu27VmIAEH/BZVW8EZSsE339ONmT8COnLjt9+XQua6yyv1jCgltHeqXWUrxza12zOWicaasMSRGmQmwv70wKaJTYfr4Hs2eqc2/CpUNVNHBfkrXXUaArn1QjbSzjrZB+F37bkaw5ybwfyzW1VpU7BJsKaFzg1wPLnFU88xw7BzpV5k8bebc4yiYDaLZ0mKV/SiL7IqbWac54liHNZTjbs/SmgtrHpeLPGvu3Hf3WC01zhO3hFNXDOc1RrcPz+ufYrNHO/06yz56e879tvm2BfWr73rka+2lrT44m3QmR44j/4K6R/lzdpZLrTrZQ7D+rGQ0xATSOqgdUuz0GWIExw2Uedg1/+8x2/bYH9O0Bz8q5fqUbehJE/iZwtzVe5Oc7B88AO2L/TSQL7dxz/67t/7GDe7SpEBW8OqtnUSa4lnarzQyEwYexcdbx5snJ03hPg9dqFr1apCtmZwTuBZB2GrMzwxJVf2fJQrbHzP1BYk2AJZwnCnLycbOcguS/NqWns2+7c37v9eFn+A2hEhYCE4UsgAUmkav3Q/xMdO+Qe9N2D//70fAlgJxz8pWDyK1MWqpwPVes6J/mr1nfv13Nir9kMzqt5diTAk5F9DH5d4ySLNDdp7FoPuMeFGhfkPZ9xfpzTQSLba0+/IwE9BIMsO9G2nE3HJoGq9ZzOBPlv1RpBldol9rsTtgQhIr2AvwMRwKuq+kS+5Y1wZpGLBn4DBqtqmojEAy8BVXHmqJ6kqrNO9FyWIM4wVae5IjBh5E8iB3/Ot5E47fEnSiIVqwX/R8rNhcO7nAN+YALIf/A/uq/gthWqugd998Dvux9Z7/jfytElozNCSZC5D3asOF7LSEsN+CyFUzpwSxko53b8KB+sd98Jev0F6/1XtoIbS5hlHXZq4Xu2Ok25e7Y6twM7865X7jwnURRIII2c8uI6F3UKwpIgRCQCWA9cCaThTEE6UFXXBqzzDjBXVaeJSHdghKoOEZELAVXVDSJSD1gGXJx/vupAliBKoOyjzgH9REkksPcVOF2HfQmjXCWn59aBnc7f3Ky860oZJ+FE1nV+vVWtd/x+4N8KVc7cay6t9u9wksXP3wNSeJftwrp4R5Qrsb+gQyLriNNJwJcw9gQkjz1b83ZZB+d7nL/W4bsfWTekP17ClSAuASaoak/38f0Aqvp4wDprgF6qul1EBNinqlWD7GslcKOqbijs+SxBnIVU4VCGkzTyJBFfE9ZhiDw/4OBfL+8v/8q1rSeOOfuowqFdAbWOLXmTyL408tTSIsrnq300yptIKhY4ZJ6UEyWIUP531Qe2BzxOAzrmW2cl0BenGep6IFJEaqrqbt8KIpIIlAc2hTBWEw4iTttsldpO+7Yx5wIR52LGKtHQoEPB5dnHnB9IgTUO3237twWbUc+rCQ0vgQEzij3UcP/8uht4QUSGA4uAdJxzDgCISF3gDWCYamCfQv/yUcAogIYNG56JeI0xJrTKlj9+zUwwR/YUTBwh6kodygSRDjQIeBzjlvmp6g6cGgQiUgW4wXeeQUSqAh8BD6jqN8GeQFWnAFPAaWIq7hdgjDElTqXq7hArbUP+VKHstpECNBeRJiJSHhgAzAlcQURqiYgvhvtxejThrv8BMF1V3w1hjMYYYwoRsgShqtnAGOBT4AfgbVVdIyITRaSPu1o3YJ2IrAfqAJPc8j8AlwHDRWSFe4sPVazGGGMKsgvljDHmHHaiXkx2ZZAxxpigLEEYY4wJyhKEMcaYoCxBGGOMCcoShDHGmKBKTS8mEckAfjqNXdQCdhVTOGc7ey/ysvcjL3s/jisN70UjVQ06kXmpSRCnS0RSC+vqda6x9yIvez/ysvfjuNL+XlgTkzHGmKAsQRhjjAnKEsRxU8IdQAli70Ve9n7kZe/HcaX6vbBzEMYYY4KyGoQxxpigLEEYY4wJ6pxPECLSS0TWichGEbkv3PGEk4g0EJEFIrJWRNaIyJ/CHVO4iUiEiCwXkbnhjiXcRKSaiLwrIj+KyA/uvPPnLBH5s/t/slpEZopIxXDHVNzO6QQhIhHAi8DVQEtgoIi0DG9UYZUN/D9VbQl0Am4/x98PgD/hzGdinLnj/6uqFwFtOIffFxGpD9wJJKhqLBCBMylaqXJOJwggEdioqptV9RjwFnBtmGMKG1XdqarfufcP4BwA6oc3qvARkRjg98Cr4Y4l3EQkCmcSr9cAVPWYb3rgc1hZoJKIlAXOA3aEOZ5id64niPrA9oDHaZzDB8RAItIYaAssDW8kYfUccA+QG+5ASoAmQAbwutvk9qqIVA53UOGiqunAZGAbsBPYp6rzwhtV8TvXE4QJQkSqAO8BY1V1f7jjCQcR6Q38qqrLwh1LCVEWaAe8pKptgUPAOXvOTkSq47Q2NAHqAZVFZHB4oyp+53qCSAcaBDyOccvOWSJSDic5zFDV98MdTxh1BvqIyFacpsfuIvJmeEMKqzQgTVV9Ncp3cRLGuaoHsEVVM1Q1C3gfuDTMMRW7cz1BpADNRaSJiJTHOck0J8wxhY2ICE4b8w+q+ky44wknVb1fVWNUtTHO92K+qpa6X4heqerPwHYRaeEWXQGsDWNI4bYN6CQi57n/N1dQCk/alw13AOGkqtkiMgb4FKcXQrKqrglzWOHUGRgCfC8iK9yyv6jqx2GMyZQcdwAz3B9Tm4ERYY4nbFR1qYi8C3yH0/tvOaVw2A0basMYY0xQ53oTkzHGmEJYgjDGGBOUJQhjjDFBWYIwxhgTlCUIY4wxQVmCMGc1EenojkC70h1hdIp7JXiJIiI3i8hiEUkVkQnhjscYL87p6yBMqVARGKKqaQAiMhpncL0SM7KmiPwfzui4vVV1X7jjMcYrq0GYs5qqfulLDu7jl4ALReQCEekmIvtEZIV7S/f9eheReBH5RkRWicgHIlJdRMqKSIqIdHPXeVxEJrn3x7vLVru1FMkfi4g0FpH57j6/EJGG7qJROEO6LHGfs7WIlBGRDSIS7W5bxp2TJFpEFopIgls+XERecO9Hi8h7bhwpItLZLZ8gIncHxDE34DUcDChf7JvXQkRquM+z0p0PZWFxfB6mdLEEYc56IjIuIAmsAJrizO8BsFhV41U1Hng2YLPpwL2q2hr4HnhIVbOB4cBLItID6AU87K7/gqp2cMf+rwT0DhLK88A0d58zgH+45bWBr1Q1DvgLMF1Vc4E3gUHuOj2AlaqagTN6bIEEhDMfw7Oq2gG4gZMYhlxEfg9EBRQNAlarapuAGIzJwxKEOeup6lO+JOAmglUnWt+d26Caqn7pFk3DmesAd6iVN4C5wEh3nhCAy0VkqYh8D3QHWgXZ9SXAv937bwBdfE/pPkZV5wM1RaQqkAwMddcZCbzu3k/DGWo9vx7AC24SnANUDTjf8ueABNk13+sV4AHgsYDiHCAyyHMY42fnIEyp4h5443EGkmtQxOqFiQP24vzyx51K8p84s4dtd5upTmZ6yaBDprv7+kVEuuNMXuX7Jf8YME1Ebgeqc3wAyTJAJ1XNDNyP29r1rKpOdh/nnx51ILAQ+Dmg7A3gahH5GdiHM6eBMXlYDcKc1dw2+rbu/QjgaZxpMTcVto17oniPiPh+aQ8BvnT30ReogVOjeF5EqnE8Gexyf7HfWMiuv+L4yfFBwGL3/lL3Me65gV0B82y8itPU9I6q5rjx/aiqHd3mn/EB+5+HM2Ce77XHF/YaA5QBxgJP5is/iDPI3BCsickUwhKEOdutAZ4Rke+ATTjNOTd72G4Y8JSIrMKpcUwUkVrAE8DNqroeeAH4uzu15r+A1Tgj/6YUss87gBHuPofgzGcN8Fegs1v+mPvcPnOAKhxvXjqRO4EE9yT4WuBWD9tUAt4LMj3oOGCVqn7mYR/mHGWjuRoTRm5vpWdVtWuRKxtzhtk5CGPCRETuA0ZjTTymhLIahDHGmKDsHIQxxpigLEEYY4wJyhKEMcaYoCxBGGOMCcoShDHGmKD+P1kEGTs/zw2/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtPn0hTNJ_On",
        "outputId": "6be8b482-7423-49f2-bbc4-ec897417a5ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data = [[1, 200, 'relu', 15000, None, round(history.history['val_accuracy'][-1], 3)]]\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 200, 'relu', 15000, None, 0.92]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxWjGE44J_Ri",
        "outputId": "079787e9-5162-41f0-d83d-c143305485f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# чистим оперативную память\n",
        "import gc    \n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODU9zovBJ_U5",
        "outputId": "52c74181-0d64-4b95-8085-7705bd23997a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 1\n",
        "maxWordsCountList = [10,1000,10000,25000]\n",
        "for i in maxWordsCountList:\n",
        "    gc.collect()\n",
        "    # Подготавливаем данные\n",
        "    _, xTrain01, yTrain, _, xTest01, yTest = creat_train_data(maxWordsCount = i, xLen = 1000, step = 100)\n",
        "    # Создаем сеть\n",
        "    model01 = Sequential()\n",
        "    model01.add(Dense(200, input_dim=i, activation=\"relu\")) # Указываем входной размер \n",
        "    model01.add(Dropout(0.25))\n",
        "    model01.add(BatchNormalization())\n",
        "    model01.add(Dense(6, activation='softmax'))\n",
        "\n",
        "    model01.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy']\n",
        "    history = model01.fit(xTrain01, yTrain, epochs=10, batch_size=128, validation_data=(xTest01, yTest))\n",
        "                      \n",
        "    data = data + [[1, 200, 'relu', i, None, round(history.history['val_accuracy'][-1], 3)]]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 1.8878 - accuracy: 0.2460 - val_loss: 1.7400 - val_accuracy: 0.3401\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.6903 - accuracy: 0.2837 - val_loss: 1.6800 - val_accuracy: 0.3401\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.5820 - accuracy: 0.3241 - val_loss: 1.6653 - val_accuracy: 0.3401\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.5378 - accuracy: 0.3429 - val_loss: 1.6736 - val_accuracy: 0.3401\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.4979 - accuracy: 0.3488 - val_loss: 1.6738 - val_accuracy: 0.3401\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.4918 - accuracy: 0.3606 - val_loss: 1.6680 - val_accuracy: 0.3401\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.4761 - accuracy: 0.3672 - val_loss: 1.6655 - val_accuracy: 0.3401\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.4566 - accuracy: 0.3780 - val_loss: 1.6683 - val_accuracy: 0.3401\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.4548 - accuracy: 0.3727 - val_loss: 1.6709 - val_accuracy: 0.3401\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.4459 - accuracy: 0.3839 - val_loss: 1.6654 - val_accuracy: 0.3401\n",
            "Epoch 1/10\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.2239 - accuracy: 0.9304 - val_loss: 0.3908 - val_accuracy: 0.8833\n",
            "Epoch 2/10\n",
            "85/85 [==============================] - 1s 6ms/step - loss: 0.0086 - accuracy: 0.9998 - val_loss: 0.3163 - val_accuracy: 0.9012\n",
            "Epoch 3/10\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9037\n",
            "Epoch 4/10\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9047\n",
            "Epoch 5/10\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9077\n",
            "Epoch 6/10\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9067\n",
            "Epoch 7/10\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9004\n",
            "Epoch 8/10\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 8.7690e-04 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9060\n",
            "Epoch 9/10\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 7.1990e-04 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9014\n",
            "Epoch 10/10\n",
            "85/85 [==============================] - 0s 5ms/step - loss: 5.4143e-04 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9012\n",
            "Epoch 1/10\n",
            "115/115 [==============================] - 5s 41ms/step - loss: 0.0544 - accuracy: 0.9822 - val_loss: 0.3197 - val_accuracy: 0.9015\n",
            "Epoch 2/10\n",
            "115/115 [==============================] - 5s 40ms/step - loss: 6.3985e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9030\n",
            "Epoch 3/10\n",
            "115/115 [==============================] - 4s 39ms/step - loss: 3.3255e-04 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9007\n",
            "Epoch 4/10\n",
            "115/115 [==============================] - 4s 39ms/step - loss: 2.1870e-04 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9007\n",
            "Epoch 5/10\n",
            "115/115 [==============================] - 4s 39ms/step - loss: 1.6125e-04 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8996\n",
            "Epoch 6/10\n",
            "115/115 [==============================] - 4s 39ms/step - loss: 1.3189e-04 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9002\n",
            "Epoch 7/10\n",
            "115/115 [==============================] - 5s 39ms/step - loss: 1.0010e-04 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9004\n",
            "Epoch 8/10\n",
            "115/115 [==============================] - 4s 39ms/step - loss: 8.1886e-05 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9013\n",
            "Epoch 9/10\n",
            "115/115 [==============================] - 5s 40ms/step - loss: 7.2837e-05 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9017\n",
            "Epoch 10/10\n",
            "115/115 [==============================] - 5s 39ms/step - loss: 5.5760e-05 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9038\n",
            "Epoch 1/10\n",
            "127/127 [==============================] - 12s 96ms/step - loss: 0.0423 - accuracy: 0.9864 - val_loss: 0.2964 - val_accuracy: 0.9139\n",
            "Epoch 2/10\n",
            "127/127 [==============================] - 12s 94ms/step - loss: 7.4418e-04 - accuracy: 0.9999 - val_loss: 0.2849 - val_accuracy: 0.9146\n",
            "Epoch 3/10\n",
            "127/127 [==============================] - 12s 94ms/step - loss: 4.1366e-04 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.9082\n",
            "Epoch 4/10\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 2.2006e-04 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.8984\n",
            "Epoch 5/10\n",
            "127/127 [==============================] - 12s 95ms/step - loss: 1.5531e-04 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.8958\n",
            "Epoch 6/10\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 3.7007e-04 - accuracy: 0.9999 - val_loss: 0.3322 - val_accuracy: 0.8932\n",
            "Epoch 7/10\n",
            "127/127 [==============================] - 12s 94ms/step - loss: 5.0463e-04 - accuracy: 0.9999 - val_loss: 0.3254 - val_accuracy: 0.9036\n",
            "Epoch 8/10\n",
            "127/127 [==============================] - 12s 94ms/step - loss: 1.4294e-04 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.8807\n",
            "Epoch 9/10\n",
            "127/127 [==============================] - 12s 92ms/step - loss: 2.6527e-04 - accuracy: 0.9999 - val_loss: 0.3756 - val_accuracy: 0.8719\n",
            "Epoch 10/10\n",
            "127/127 [==============================] - 12s 93ms/step - loss: 1.5015e-04 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.8699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qrJN3ByDTWU",
        "outputId": "f6c9a44a-21c2-43af-faae-fed73adf8347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 2.1\n",
        "_, xTrain01, yTrain, _, xTest01, yTest = creat_train_data(maxWordsCount = 20000, xLen = 1000, step = 100)\n",
        "neurons_list = [10, 50, 100, 500, 1000, 2000]\n",
        "\n",
        "for i in neurons_list:\n",
        "    gc.collect()\n",
        "    # Создаем сеть\n",
        "    model01 = Sequential()\n",
        "    model01.add(Dense(i, input_dim=20000, activation=\"relu\"))\n",
        "    model01.add(Dropout(0.25))\n",
        "    model01.add(BatchNormalization())\n",
        "    model01.add(Dense(6, activation='softmax'))\n",
        "\n",
        "    model01.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model01.fit(xTrain01, yTrain, epochs=10, batch_size=128, validation_data=(xTest01, yTest))\n",
        "    data = data + [[1, i, 'relu', 20000, None, round(history.history['val_accuracy'][-1], 3)]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "124/124 [==============================] - 2s 14ms/step - loss: 0.5827 - accuracy: 0.8859 - val_loss: 0.7303 - val_accuracy: 0.8373\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.2391 - accuracy: 0.9660 - val_loss: 0.5577 - val_accuracy: 0.8932\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.1657 - accuracy: 0.9698 - val_loss: 0.4874 - val_accuracy: 0.8960\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.1281 - accuracy: 0.9738 - val_loss: 0.4248 - val_accuracy: 0.9069\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.1067 - accuracy: 0.9781 - val_loss: 0.3990 - val_accuracy: 0.9039\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.0899 - accuracy: 0.9812 - val_loss: 0.3830 - val_accuracy: 0.9084\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.0794 - accuracy: 0.9833 - val_loss: 0.3808 - val_accuracy: 0.8965\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.0766 - accuracy: 0.9823 - val_loss: 0.3352 - val_accuracy: 0.9202\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.0702 - accuracy: 0.9838 - val_loss: 0.3511 - val_accuracy: 0.8941\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.0611 - accuracy: 0.9870 - val_loss: 0.3862 - val_accuracy: 0.8770\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 3s 27ms/step - loss: 0.1065 - accuracy: 0.9760 - val_loss: 0.3545 - val_accuracy: 0.9232\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 3s 25ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9362\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 3s 26ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9369\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 3s 25ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9383\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 3s 25ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9376\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 3s 26ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9339\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 3s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9378\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 3s 26ms/step - loss: 8.7220e-04 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9366\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 3s 25ms/step - loss: 6.4062e-04 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9306\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 3s 25ms/step - loss: 5.6803e-04 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9346\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.0587 - accuracy: 0.9824 - val_loss: 0.3007 - val_accuracy: 0.9302\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9357\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 7.9700e-04 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9360\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 4.9168e-04 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9358\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 3.3118e-04 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9374\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 2.5156e-04 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9383\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 1.9895e-04 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9388\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 1.5343e-04 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9388\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 5s 44ms/step - loss: 1.3758e-04 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9387\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 6s 45ms/step - loss: 1.1801e-04 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9390\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 22s 181ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.3270 - val_accuracy: 0.8958\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 22s 180ms/step - loss: 7.9425e-05 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9043\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 23s 183ms/step - loss: 3.7010e-05 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9036\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 23s 183ms/step - loss: 2.3559e-05 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9036\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 23s 187ms/step - loss: 1.6087e-05 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9064\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 23s 182ms/step - loss: 1.4677e-05 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9084\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 22s 180ms/step - loss: 1.0118e-05 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9066\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 22s 180ms/step - loss: 7.5971e-06 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9073\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 22s 180ms/step - loss: 6.1424e-06 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9080\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 22s 177ms/step - loss: 5.6361e-06 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9096\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 44s 353ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 0.3513 - val_accuracy: 0.8844\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 44s 353ms/step - loss: 4.4499e-05 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9002\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 44s 352ms/step - loss: 2.1003e-05 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.8994\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 44s 353ms/step - loss: 1.6601e-05 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.9001\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 45s 365ms/step - loss: 9.1662e-06 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8994\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 45s 364ms/step - loss: 7.3823e-06 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.8980\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 48s 383ms/step - loss: 5.9586e-06 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.8978\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 4.7881e-06 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.8987\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 44s 357ms/step - loss: 3.7621e-06 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.8983\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 43s 346ms/step - loss: 2.8885e-06 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.8988\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 92s 741ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.4337 - val_accuracy: 0.8488\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 90s 729ms/step - loss: 2.2108e-05 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9092\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 91s 737ms/step - loss: 1.3045e-05 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9112\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 92s 741ms/step - loss: 8.5577e-06 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9092\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 90s 726ms/step - loss: 5.2026e-06 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9099\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 91s 731ms/step - loss: 4.2729e-06 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9114\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 91s 738ms/step - loss: 2.5478e-06 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9117\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 91s 734ms/step - loss: 2.5707e-06 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9110\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 91s 735ms/step - loss: 1.8196e-06 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9108\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 92s 738ms/step - loss: 2.3490e-06 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12aj76KgDTZe",
        "outputId": "e948c3b9-964a-4302-acb3-16f31bd107f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 2.2\n",
        "for i in neurons_list:\n",
        "    gc.collect()\n",
        "    # Создаем сеть\n",
        "    model01 = Sequential()\n",
        "    model01.add(Dense(i, input_dim=20000, activation=\"relu\"))\n",
        "    model01.add(Dense(i, activation=\"relu\"))               \n",
        "    model01.add(Dropout(0.25))\n",
        "    model01.add(BatchNormalization())\n",
        "    model01.add(Dense(6, activation='softmax'))\n",
        "\n",
        "    model01.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model01.fit(xTrain01, yTrain, epochs=10, batch_size=128, validation_data=(xTest01, yTest))\n",
        "    data = data + [[2, i, 'relu', 20000, None, round(history.history['val_accuracy'][-1], 3)]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "124/124 [==============================] - 2s 13ms/step - loss: 0.7387 - accuracy: 0.8001 - val_loss: 1.0653 - val_accuracy: 0.6567\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 1s 12ms/step - loss: 0.3194 - accuracy: 0.9333 - val_loss: 0.8526 - val_accuracy: 0.7571\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.2185 - accuracy: 0.9609 - val_loss: 0.7035 - val_accuracy: 0.7741\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.1682 - accuracy: 0.9646 - val_loss: 0.6295 - val_accuracy: 0.7790\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.1429 - accuracy: 0.9660 - val_loss: 0.5897 - val_accuracy: 0.7880\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.1208 - accuracy: 0.9670 - val_loss: 0.5314 - val_accuracy: 0.8100\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.1100 - accuracy: 0.9679 - val_loss: 0.5986 - val_accuracy: 0.7697\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.0995 - accuracy: 0.9701 - val_loss: 0.4968 - val_accuracy: 0.8167\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 1s 12ms/step - loss: 0.0917 - accuracy: 0.9707 - val_loss: 0.5452 - val_accuracy: 0.7871\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 1s 11ms/step - loss: 0.0856 - accuracy: 0.9721 - val_loss: 0.4676 - val_accuracy: 0.8176\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 3s 27ms/step - loss: 0.1756 - accuracy: 0.9604 - val_loss: 0.3623 - val_accuracy: 0.9284\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 3s 26ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9395\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 3s 26ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9432\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 3s 26ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9408\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 3s 26ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9425\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 3s 25ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9381\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 3s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9392\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 3s 26ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9461\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 3s 26ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9406\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 3s 25ms/step - loss: 9.7484e-04 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9408\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 6s 44ms/step - loss: 0.0818 - accuracy: 0.9791 - val_loss: 0.3289 - val_accuracy: 0.9320\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9336\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9313\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 5s 42ms/step - loss: 7.4131e-04 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9321\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 5.0493e-04 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9321\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 3.7754e-04 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9323\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 3.0642e-04 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9320\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 2.2965e-04 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9334\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 1.9177e-04 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9364\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 5s 43ms/step - loss: 1.5844e-04 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9378\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 23s 187ms/step - loss: 0.0427 - accuracy: 0.9862 - val_loss: 0.2383 - val_accuracy: 0.9230\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 23s 186ms/step - loss: 1.2582e-04 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9221\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 23s 187ms/step - loss: 6.6312e-05 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9179\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 23s 187ms/step - loss: 4.1254e-05 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9179\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 23s 186ms/step - loss: 2.8593e-05 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9189\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 23s 187ms/step - loss: 2.1929e-05 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9207\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 23s 183ms/step - loss: 1.7834e-05 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9196\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 23s 183ms/step - loss: 1.3941e-05 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9202\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 24s 194ms/step - loss: 1.0994e-05 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9189\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 25s 200ms/step - loss: 9.5026e-06 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9193\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 49s 393ms/step - loss: 0.0357 - accuracy: 0.9882 - val_loss: 0.3759 - val_accuracy: 0.8669\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 50s 404ms/step - loss: 4.3589e-05 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.8930\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 49s 394ms/step - loss: 2.4170e-05 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.8999\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 46s 372ms/step - loss: 1.2242e-05 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.8994\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 46s 370ms/step - loss: 9.0980e-06 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9022\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 46s 374ms/step - loss: 6.8082e-06 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9020\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 46s 371ms/step - loss: 5.5024e-06 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9024\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 46s 369ms/step - loss: 4.4973e-06 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.9025\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 46s 368ms/step - loss: 3.5796e-06 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9032\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 46s 371ms/step - loss: 2.7056e-06 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9027\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 102s 824ms/step - loss: 0.0317 - accuracy: 0.9894 - val_loss: 0.3585 - val_accuracy: 0.8851\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 102s 819ms/step - loss: 2.8328e-05 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.8891\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 101s 816ms/step - loss: 1.3142e-05 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.8890\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 102s 819ms/step - loss: 8.3295e-06 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.8870\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 101s 812ms/step - loss: 5.8106e-06 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.8847\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 102s 824ms/step - loss: 4.1701e-06 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.8847\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 104s 835ms/step - loss: 3.0932e-06 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.8846\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 103s 833ms/step - loss: 2.7559e-06 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.8858\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 103s 833ms/step - loss: 2.3915e-06 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.8877\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 109s 880ms/step - loss: 1.8736e-06 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.8877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEHp5SfLDTcb"
      },
      "source": [
        "# 2.3\n",
        "\n",
        "gc.collect()\n",
        "model01 = Sequential()\n",
        "model01.add(Dense(200, input_dim=20000, activation=\"linear\"))\n",
        "model01.add(Dropout(0.25))\n",
        "model01.add(BatchNormalization())\n",
        "model01.add(Dense(6, activation='softmax'))\n",
        "\n",
        "model01.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model01.fit(xTrain01, yTrain, epochs=10, batch_size=128, validation_data=(xTest01, yTest))\n",
        "data = data + [[1, 200, 'linear', 20000, None, round(history.history['val_accuracy'][-1], 3)]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIVRoPnVC4Kc",
        "outputId": "70406343-4e2f-4454-c202-b75c6473a5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "df = pd.DataFrame(data, columns = ['Layers', 'Neurons', 'Activation','MaxWordCount', 'Emb_size', 'val_accuracy'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Layers</th>\n",
              "      <th>Neurons</th>\n",
              "      <th>Activation</th>\n",
              "      <th>MaxWordCount</th>\n",
              "      <th>Emb_size</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>relu</td>\n",
              "      <td>15000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>relu</td>\n",
              "      <td>10</td>\n",
              "      <td>None</td>\n",
              "      <td>0.340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>relu</td>\n",
              "      <td>1000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>relu</td>\n",
              "      <td>10000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>relu</td>\n",
              "      <td>25000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2</td>\n",
              "      <td>500</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2</td>\n",
              "      <td>2000</td>\n",
              "      <td>relu</td>\n",
              "      <td>20000</td>\n",
              "      <td>None</td>\n",
              "      <td>0.888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Layers  Neurons Activation  MaxWordCount Emb_size  val_accuracy\n",
              "0        1      200       relu         15000     None         0.920\n",
              "1        1      200       relu            10     None         0.340\n",
              "2        1      200       relu          1000     None         0.901\n",
              "3        1      200       relu         10000     None         0.904\n",
              "4        1      200       relu         25000     None         0.870\n",
              "5        1       10       relu         20000     None         0.877\n",
              "6        1       50       relu         20000     None         0.935\n",
              "7        1      100       relu         20000     None         0.939\n",
              "8        1      500       relu         20000     None         0.910\n",
              "9        1     1000       relu         20000     None         0.899\n",
              "10       1     2000       relu         20000     None         0.911\n",
              "11       2       10       relu         20000     None         0.818\n",
              "12       2       50       relu         20000     None         0.941\n",
              "13       2      100       relu         20000     None         0.938\n",
              "14       2      500       relu         20000     None         0.919\n",
              "15       2     1000       relu         20000     None         0.903\n",
              "16       2     2000       relu         20000     None         0.888"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxCTh4L5C4Nh",
        "outputId": "15872260-cfb8-4802-c3a2-9fe2dd2f6507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 3 \n",
        "import gc\n",
        "maxWordsCount = 50000\n",
        "xLen = 1000\n",
        "step = 100\n",
        "xTrain, _, yTrain, xTest, _, yTest = creat_train_data(maxWordsCount=maxWordsCount, xLen=xLen, step=step)\n",
        "data = []\n",
        "emb_list = [10, 50 ,200]\n",
        "\n",
        "for i in emb_list:\n",
        "    gc.collect()\n",
        "    modelE = Sequential()\n",
        "    modelE.add(Embedding(50000, i, input_length=xLen))\n",
        "    modelE.add(SpatialDropout1D(0.2))\n",
        "    modelE.add(Flatten())\n",
        "    modelE.add(BatchNormalization())\n",
        "    modelE.add(Dense(200, activation=\"relu\"))\n",
        "    modelE.add(Dropout(0.2))\n",
        "    modelE.add(BatchNormalization())\n",
        "    modelE.add(Dense(6, activation='softmax'))\n",
        "\n",
        "    modelE.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = modelE.fit(xTrain, yTrain, epochs=10, batch_size=128, validation_data=(xTest, yTest))\n",
        "    data = data + [[1, 200, 'relu', 50000, i, round(history.history['val_accuracy'][-1], 3)]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "134/134 [==============================] - 12s 89ms/step - loss: 0.6826 - accuracy: 0.7632 - val_loss: 1.4743 - val_accuracy: 0.3295\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 12s 89ms/step - loss: 0.0254 - accuracy: 0.9950 - val_loss: 1.2216 - val_accuracy: 0.4654\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 12s 87ms/step - loss: 0.0142 - accuracy: 0.9967 - val_loss: 0.9307 - val_accuracy: 0.6384\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 11s 85ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.7676 - val_accuracy: 0.7361\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 11s 85ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.7056 - val_accuracy: 0.7661\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 11s 86ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.8390 - val_accuracy: 0.7469\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 11s 85ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.7029 - val_accuracy: 0.7784\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 11s 86ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.9816 - val_accuracy: 0.7300\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 11s 86ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.8203 - val_accuracy: 0.7601\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 11s 85ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.9812 - val_accuracy: 0.7326\n",
            "Epoch 1/10\n",
            "134/134 [==============================] - 56s 417ms/step - loss: 0.4474 - accuracy: 0.8613 - val_loss: 1.8316 - val_accuracy: 0.3019\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 55s 412ms/step - loss: 0.0071 - accuracy: 0.9998 - val_loss: 1.3904 - val_accuracy: 0.3562\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 56s 420ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9484 - val_accuracy: 0.6028\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 55s 414ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.6959 - val_accuracy: 0.7434\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 55s 413ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.7609\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 55s 413ms/step - loss: 8.2503e-04 - accuracy: 1.0000 - val_loss: 0.7368 - val_accuracy: 0.7612\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 56s 417ms/step - loss: 5.6035e-04 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.7601\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 56s 416ms/step - loss: 5.1133e-04 - accuracy: 1.0000 - val_loss: 0.7782 - val_accuracy: 0.7596\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 55s 413ms/step - loss: 3.8310e-04 - accuracy: 1.0000 - val_loss: 0.7526 - val_accuracy: 0.7661\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 56s 418ms/step - loss: 3.1732e-04 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.7668\n",
            "Epoch 1/10\n",
            "134/134 [==============================] - 203s 2s/step - loss: 0.3683 - accuracy: 0.8944 - val_loss: 1.7768 - val_accuracy: 0.3012\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 205s 2s/step - loss: 0.0075 - accuracy: 0.9999 - val_loss: 1.3190 - val_accuracy: 0.3995\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 205s 2s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9447 - val_accuracy: 0.6190\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 202s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.7315\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 203s 2s/step - loss: 8.9930e-04 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.7519\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 201s 2s/step - loss: 6.0285e-04 - accuracy: 1.0000 - val_loss: 0.7331 - val_accuracy: 0.7529\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 203s 2s/step - loss: 4.4486e-04 - accuracy: 1.0000 - val_loss: 0.7546 - val_accuracy: 0.7509\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 202s 2s/step - loss: 3.7364e-04 - accuracy: 1.0000 - val_loss: 0.7612 - val_accuracy: 0.7519\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 200s 1s/step - loss: 2.7697e-04 - accuracy: 1.0000 - val_loss: 0.7643 - val_accuracy: 0.7526\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 203s 2s/step - loss: 2.3288e-04 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.7547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyLxMcneC4Qh",
        "outputId": "eaf805c6-1835-4528-bed9-cc3e7b842e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "df = pd.DataFrame(data, columns = ['Layers', 'Neurons', 'Activation','MaxWordCount', 'Emb_size', 'val_accuracy'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Layers</th>\n",
              "      <th>Neurons</th>\n",
              "      <th>Activation</th>\n",
              "      <th>MaxWordCount</th>\n",
              "      <th>Emb_size</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>relu</td>\n",
              "      <td>50000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>relu</td>\n",
              "      <td>50000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>relu</td>\n",
              "      <td>50000</td>\n",
              "      <td>200</td>\n",
              "      <td>0.755</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Layers  Neurons Activation  MaxWordCount  Emb_size  val_accuracy\n",
              "0       1      200       relu         50000        10         0.733\n",
              "1       1      200       relu         50000        50         0.767\n",
              "2       1      200       relu         50000       200         0.755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}